[
    {
        "year": 2025,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality",
                "container-title": "arXiv preprint arXiv:2503.24277",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanistic interpretability, but leading SAE approaches with top- style activation functions lack theoretical grounding for selecting the hyperparameter . SAEs are based on the linear representation hypothesis (LRH), which assumes that the representations of large language models (LLMs) are linearly encoded, and the superposition hypothesis (SH), which states that there can be more features in the model than its dimensionality. We show that, based on the formal definitions of the LRH and SH, the magnitude of sparse feature vectors (the latent representations learned by SAEs of the dense embeddings of LLMs) can be approximated using their corresponding dense vector with a closed-form error bound. To visualize this, we propose the ZF plot, which reveals a previously unknown relationship between LLM hidden embeddings and SAE feature vectors, allowing us to make the first empirical measurement of the extent to which feature vectors of pre-trained SAEs are over- or under-activated for a given input. Correspondingly, we introduce Approximate Feature Activation (AFA), which approximates the magnitude of the ground-truth sparse feature vector, and propose a new evaluation metric derived from AFA to assess the alignment between inputs and activations. We also leverage AFA to introduce a novel SAE architecture, the top-AFA SAE, leading to SAEs that: (a) are more in line with theoretical justifications; and (b) obviate the need to tune SAE sparsity hyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achieve reconstruction loss comparable to that …",
                "DOI": "",
                "author": [
                    {
                        "family": "Lee",
                        "given": "Sewoong"
                    },
                    {
                        "family": "Davies",
                        "given": "Adam"
                    },
                    {
                        "family": "Canby",
                        "given": "Marc E"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2503.24277",
                "issued": {
                    "date-parts": [
                        [
                            2025
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Scaling Evaluation-time Compute with Reasoning Models as Process Evaluators",
                "container-title": "arXiv preprint arXiv:2503.19877",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "As language model (LM) outputs get more and more natural, it is becoming more difficult than ever to evaluate their quality. Simultaneously, increasing LMs' \"thinking\" time through scaling test-time compute has proven an effective technique to solve challenging problems in domains such as math and code. This raises a natural question: can an LM's evaluation capability also be improved by spending more test-time compute? To answer this, we investigate employing reasoning models-LMs that natively generate long chain-of-thought reasoning-as evaluators. Specifically, we examine methods to leverage more test-time compute by (1) using reasoning models, and (2) prompting these models to evaluate not only the response as a whole (i.e., outcome evaluation) but also assess each step in the response separately (i.e., process evaluation). In experiments, we observe that the evaluator's performance improves monotonically when generating more reasoning tokens, similar to the trends observed in LM-based generation. Furthermore, we use these more accurate evaluators to rerank multiple generations, and demonstrate that spending more compute at evaluation time can be as effective as using more compute at generation time in improving an LM's problem-solving capability.",
                "DOI": "",
                "author": [
                    {
                        "family": "Kim",
                        "given": "Seungone"
                    },
                    {
                        "family": "Wu",
                        "given": "Ian"
                    },
                    {
                        "family": "Lee",
                        "given": "Jinu"
                    },
                    {
                        "family": "Yue",
                        "given": "Xiang"
                    },
                    {
                        "family": "Lee",
                        "given": "Seongyun"
                    },
                    {
                        "family": "Moon",
                        "given": "Mingyeong"
                    },
                    {
                        "family": "Gashteovski",
                        "given": "Kiril"
                    },
                    {
                        "family": "Lawrence",
                        "given": "Carolin"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Neubig",
                        "given": "Graham"
                    },
                    {
                        "family": "Welleck",
                        "given": "Sean"
                    }
                ],
                "link": "https://arxiv.org/abs/2503.19877",
                "issued": {
                    "date-parts": [
                        [
                            2025
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "RAG-RL: Advancing Retrieval-Augmented Generation via RL and Curriculum Learning",
                "container-title": "arXiv preprint arXiv:2503.12759",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Recent research highlights the challenges retrieval models face in retrieving useful contexts and the limitations of generation models in effectively utilizing those contexts in retrieval-augmented generation (RAG) settings. To address these challenges, we introduce RAG-RL, the first reasoning language model (RLM) specifically trained for RAG. RAG-RL demonstrates that stronger answer generation models can identify relevant contexts within larger sets of retrieved information -- thereby alleviating the burden on retrievers -- while also being able to utilize those contexts more effectively. Moreover, we show that curriculum design in the reinforcement learning (RL) post-training process is a powerful approach to enhancing model performance. We benchmark our method on two open-domain question-answering datasets and achieve state-of-the-art results, surpassing previous SOTA generative reader models. In addition, we offers empirical insights into various curriculum learning strategies, providing a deeper understanding of their impact on model performance.",
                "DOI": "",
                "author": [
                    {
                        "family": "Huang",
                        "given": "Jerry"
                    },
                    {
                        "family": "Madala",
                        "given": "Siddarth"
                    },
                    {
                        "family": "Sidhu",
                        "given": "Risham"
                    },
                    {
                        "family": "Niu",
                        "given": "Cheng"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Zhang",
                        "given": "Tong"
                    }
                ],
                "link": "https://arxiv.org/abs/2503.12759",
                "issued": {
                    "date-parts": [
                        [
                            2025
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Entailment-Preserving First-order Logic Representations in Natural Language Entailment",
                "container-title": "arXiv preprint arXiv:2502.16757",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "First-order logic (FOL) can represent the logical entailment semantics of natural language (NL) sentences, but determining natural language entailment using FOL remains a challenge. To address this, we propose the Entailment-Preserving FOL representations (EPF) task and introduce reference-free evaluation metrics for EPF, the Entailment-Preserving Rate (EPR) family. In EPF, one should generate FOL representations from multi-premise natural language entailment data (e.g. EntailmentBank) so that the automatic prover's result preserves the entailment labels. Experiments show that existing methods for NL-to-FOL translation struggle in EPF. To this extent, we propose a training method specialized for the task, iterative learning-to-rank, which directly optimizes the model's EPR score through a novel scoring function and a learning-to-rank objective. Our method achieves a 1.8-2.7% improvement in EPR and a 17.4-20.6% increase in EPR@16 compared to diverse baselines in three datasets. Further analyses reveal that iterative learning-to-rank effectively suppresses the arbitrariness of FOL representation by reducing the diversity of predicate signatures, and maintains strong performance across diverse inference types and out-of-domain data.",
                "DOI": "",
                "author": [
                    {
                        "family": "Lee",
                        "given": "Jinu"
                    },
                    {
                        "family": "Liu",
                        "given": "Qi"
                    },
                    {
                        "family": "Ma",
                        "given": "Runzhi"
                    },
                    {
                        "family": "Han",
                        "given": "Vincent"
                    },
                    {
                        "family": "Wang",
                        "given": "Ziqi"
                    },
                    {
                        "family": "Ji",
                        "given": "Heng"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2502.16757",
                "issued": {
                    "date-parts": [
                        [
                            2025
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Evaluating step-by-step reasoning traces: A survey",
                "container-title": "arXiv preprint arXiv:2502.12289",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Step-by-step reasoning is widely used to enhance the reasoning ability of large language models (LLMs) in complex problems. Evaluating the quality of reasoning traces is crucial for understanding and improving LLM reasoning. However, the evaluation criteria remain highly unstandardized, leading to fragmented efforts in developing metrics and meta-evaluation benchmarks. To address this gap, this survey provides a comprehensive overview of step-by-step reasoning evaluation, proposing a taxonomy of evaluation criteria with four top-level categories (groundedness, validity, coherence, and utility). We then categorize metrics based on their implementations, survey which metrics are used for assessing each criterion, and explore whether evaluator models can transfer across different criteria. Finally, we identify key directions for future research.",
                "DOI": "",
                "author": [
                    {
                        "family": "Lee",
                        "given": "Jinu"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2502.12289",
                "issued": {
                    "date-parts": [
                        [
                            2025
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "BAP v2: An Enhanced Task Framework for Instruction Following in Minecraft Dialogues",
                "container-title": "arXiv preprint arXiv:2501.10836",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Interactive agents capable of understanding and executing instructions in the physical world have long been a central goal in AI research. The Minecraft Collaborative Building Task (MCBT) provides one such setting to work towards this goal (Narayan-Chen, Jayannavar, and Hockenmaier 2019). It is a two-player game in which an Architect (A) instructs a Builder (B) to construct a target structure in a simulated Blocks World Environment. We focus on the challenging Builder Action Prediction (BAP) subtask of predicting correct action sequences in a given multimodal game context with limited training data (Jayannavar, Narayan-Chen, and Hockenmaier 2020). We take a closer look at evaluation and data for the BAP task, discovering key challenges and making significant improvements on both fronts to propose BAP v2, an upgraded version of the task. This will allow future work to make more efficient and meaningful progress on it. It comprises of: (1) an enhanced evaluation benchmark that includes a cleaner test set and fairer, more insightful metrics, and (2) additional synthetic training data generated from novel Minecraft dialogue and target structure simulators emulating the MCBT. We show that the synthetic data can be used to train more performant and robust neural models even with relatively simple training methods. Looking ahead, such data could also be crucial for training more sophisticated, data-hungry deep transformer models and training/fine-tuning increasingly large LLMs. Although modeling is not the primary focus of this work, we also illustrate the impact of our data and training methodologies on a simple LLM- and transformer …",
                "DOI": "",
                "author": [
                    {
                        "family": "Jayannavar",
                        "given": "Prashant"
                    },
                    {
                        "family": "Ren",
                        "given": "Liliang"
                    },
                    {
                        "family": "Hudspeth",
                        "given": "Marisa"
                    },
                    {
                        "family": "Lambert",
                        "given": "Charlotte"
                    },
                    {
                        "family": "Cordes",
                        "given": "Ariel"
                    },
                    {
                        "family": "Kaplan",
                        "given": "Elizabeth"
                    },
                    {
                        "family": "Narayan-Chen",
                        "given": "Anjali"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2501.10836",
                "issued": {
                    "date-parts": [
                        [
                            2025
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2024,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Tutor-ICL: Guiding Large Language Models for Improved In-Context Learning Performance",
                "container-title": "",
                "page": "9496-9506",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "There has been a growing body of work focusing on the in-context learning (ICL) abilities of large language models (LLMs). However, it is an open question how effective ICL can be. This paper presents Tutor-ICL, a simple prompting method for classification tasks inspired by how effective instructors might engage their students in learning a task. Specifically, we propose presenting exemplar answers in a* comparative format* rather than the traditional single-answer format. We also show that including the test instance before the exemplars can improve performance, making it easier for LLMs to focus on relevant exemplars. Lastly, we include a summarization step before attempting the test, following a common human practice. Experiments on various classification tasks, conducted across both decoder-only LLMs (Llama 2, 3) and encoder-decoder LLMs (Flan-T5-XL, XXL), show that Tutor-ICL consistently boosts performance, achieving up to a 13.76% increase in accuracy.",
                "DOI": "",
                "author": [
                    {
                        "family": "Cho",
                        "given": "Ikhyun"
                    },
                    {
                        "family": "Kwon",
                        "given": "Gaeul"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/2024.findings-emnlp.554/",
                "issued": {
                    "date-parts": [
                        [
                            2024
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Measuring the reliability of causal probing methods: Tradeoffs, limitations, and the plight of nullifying interventions",
                "container-title": "arXiv preprint arXiv:2408.15510",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Causal probing is an approach to interpreting foundation models, such as large language models, by training probes to recognize latent properties of interest from embeddings, intervening on probes to modify this representation, and analyzing the resulting changes in the model's behavior. While some recent works have cast doubt on the theoretical basis of several leading causal probing intervention methods, it has been unclear how to systematically and empirically evaluate their effectiveness in practice. To address this problem, we propose a general empirical analysis framework to evaluate the reliability of causal probing interventions, formally defining and quantifying two key causal probing desiderata: completeness (fully transforming the representation of the target property) and selectivity (minimally impacting other properties). Our formalism allows us to make the first direct comparisons between different families of causal probing methods (e.g., linear vs. nonlinear or counterfactual vs. nullifying interventions). We conduct extensive experiments across several leading methods, finding that (1) there is an inherent tradeoff between these criteria, and no method is able to consistently satisfy both at once; and (2) across the board, nullifying interventions are always far less complete than counterfactual interventions, indicating that nullifying methods may not be an effective approach to causal probing.",
                "DOI": "",
                "author": [
                    {
                        "family": "Canby",
                        "given": "Marc"
                    },
                    {
                        "family": "Davies",
                        "given": "Adam"
                    },
                    {
                        "family": "Rastogi",
                        "given": "Chirag"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2408.15510",
                "issued": {
                    "date-parts": [
                        [
                            2024
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Analyzing the performance of large language models on code summarization",
                "container-title": "arXiv preprint arXiv:2404.08018",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Large language models (LLMs) such as Llama 2 perform very well on tasks that involve both natural language and source code, particularly code summarization and code generation. We show that for the task of code summarization, the performance of these models on individual examples often depends on the amount of (subword) token overlap between the code and the corresponding reference natural language descriptions in the dataset. This token overlap arises because the reference descriptions in standard datasets (corresponding to docstrings in large code bases) are often highly similar to the names of the functions they describe. We also show that this token overlap occurs largely in the function names of the code and compare the relative performance of these models after removing function names versus removing code structure. We also show that using multiple evaluation metrics like BLEU and BERTScore gives us very little additional insight since these metrics are highly correlated with each other.",
                "DOI": "",
                "author": [
                    {
                        "family": "Haldar",
                        "given": "Rajarshi"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2404.08018",
                "issued": {
                    "date-parts": [
                        [
                            2024
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "ViT-MUL: A Baseline Study on Recent Machine Unlearning Methods Applied to Vision Transformers",
                "container-title": "arXiv preprint arXiv:2403.09681",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Machine unlearning (MUL) is an arising field in machine learning that seeks to erase the learned information of specific training data points from a trained model. Despite the recent active research in MUL within computer vision, the majority of work has focused on ResNet-based models. Given that Vision Transformers (ViT) have become the predominant model architecture, a detailed study of MUL specifically tailored to ViT is essential. In this paper, we present comprehensive experiments on ViTs using recent MUL algorithms and datasets. We anticipate that our experiments, ablation studies, and findings could provide valuable insights and inspire further research in this field.",
                "DOI": "",
                "author": [
                    {
                        "family": "Cho",
                        "given": "Ikhyun"
                    },
                    {
                        "family": "Park",
                        "given": "Changyeon"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2403.09681",
                "issued": {
                    "date-parts": [
                        [
                            2024
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Attack and reset for unlearning: Exploiting adversarial noise toward machine unlearning through parameter re-initialization",
                "container-title": "arXiv preprint arXiv:2401.08998",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "With growing concerns surrounding privacy and regulatory compliance, the concept of machine unlearning has gained prominence, aiming to selectively forget or erase specific learned information from a trained model. In response to this critical need, we introduce a novel approach called Attack-and-Reset for Unlearning (ARU). This algorithm leverages meticulously crafted adversarial noise to generate a parameter mask, effectively resetting certain parameters and rendering them unlearnable. ARU outperforms current state-of-the-art results on two facial machine-unlearning benchmark datasets, MUFAC and MUCAC. In particular, we present the steps involved in attacking and masking that strategically filter and re-initialize network parameters biased towards the forget set. Our work represents a significant advancement in rendering data unexploitable to deep learning models through parameter re-initialization, achieved by harnessing adversarial noise to craft a mask.",
                "DOI": "",
                "author": [
                    {
                        "family": "Jung",
                        "given": "Yoonhwa"
                    },
                    {
                        "family": "Cho",
                        "given": "Ikhyun"
                    },
                    {
                        "family": "Hsu",
                        "given": "Shun-Hsiang"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2401.08998",
                "issued": {
                    "date-parts": [
                        [
                            2024
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Transformer language model for mapping construction schedule activities to uniformat categories",
                "container-title": "Automation in Construction",
                "page": "105183",
                "volume": "157",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Creating consistency among project schedule data, BIM, and payment applications requires activities in a construction schedule to be mapped with the most relevant ASTM Uniformat classifications. To do so, we introduce UniformatBridge, a new transformer-based natural language processing model, that automatically labels activities in a project schedule with Uniformat classification. Our model introduces construction sequencing tokens that capture logistically-constrained predecessor and successor activities into BERT architecture. We also introduce a dataset of real-world construction project schedules with their ground-truth Uniformat classifications for validation. Experimental results using this dataset achieve F1-scores of 0.93 and 0.87 when matching unstructured schedule data to Uniformat Level 2 and 3 classifications, respectively. We share how our method unlocks development of new techniques to (1 …",
                "DOI": "",
                "author": [
                    {
                        "family": "Jung",
                        "given": "Yoonhwa"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Golparvar-Fard",
                        "given": "Mani"
                    }
                ],
                "link": "https://www.sciencedirect.com/science/article/pii/S0926580523004430",
                "issued": {
                    "date-parts": [
                        [
                            2024
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2023,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "SIR-ABSC: Incorporating Syntax into RoBERTa-based Sentiment Analysis Models with a Special Aggregator Token",
                "container-title": "",
                "page": "8535-8550",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We present a simple, but effective method to incorporate syntactic dependency information directly into transformer-based language models (eg RoBERTa) for tasks such as Aspect-Based Sentiment Classification (ABSC), where the desired output depends on specific input tokens. In contrast to prior approaches to ABSC that capture syntax by combining language models with graph neural networks over dependency trees, our model, Syntax-Integrated RoBERTa for ABSC (SIR-ABSC) incorporates syntax directly into the language model by using a novel aggregator token. Yet, SIR-ABSC outperforms these more complex models, yielding new state-of-the-art results on ABSC.",
                "DOI": "",
                "author": [
                    {
                        "family": "Cho",
                        "given": "Ikhyun"
                    },
                    {
                        "family": "Jung",
                        "given": "Yoonhwa"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/2023.findings-emnlp.572/",
                "issued": {
                    "date-parts": [
                        [
                            2023
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "A Framework for Bidirectional Decoding: Case Study in Morphological Inflection",
                "container-title": "arXiv preprint arXiv:2305.12580",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Transformer-based encoder-decoder models that generate outputs in a left-to-right fashion have become standard for sequence-to-sequence tasks. In this paper, we propose a framework for decoding that produces sequences from the \"outside-in\": at each step, the model chooses to generate a token on the left, on the right, or join the left and right sequences. We argue that this is more principled than prior bidirectional decoders. Our proposal supports a variety of model architectures and includes several training methods, such as a dynamic programming algorithm that marginalizes out the latent ordering variable. Our model sets state-of-the-art (SOTA) on the 2022 and 2023 shared tasks, beating the next best systems by over 4.7 and 2.7 points in average accuracy respectively. The model performs particularly well on long sequences, can implicitly learn the split point of words composed of stem and affix, and performs better relative to the baseline on datasets that have fewer unique lemmas (but more examples per lemma).",
                "DOI": "",
                "author": [
                    {
                        "family": "Canby",
                        "given": "Marc E"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2305.12580",
                "issued": {
                    "date-parts": [
                        [
                            2023
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Graph-based event schema induction for information retrieval",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Systems, devices, computer-implemented methods, and/or computer program products that facilitate event schema induction from unstructured or semi-structured data. In one example, a system can comprise a processor that executes computer executable components stored in memory. The computer executable components can comprise a schema component and a retrieval component. The schema component can derive an event schema for a document corpus using parsing results obtained from the document corpus. The retrieval component can populate a response to a query with a document of the document corpus using events extracted from the query and the document using the event schema.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia Constanze"
                    }
                ],
                "link": "https://experts.illinois.edu/en/publications/graph-based-event-schema-induction-for-information-retrieval",
                "issued": {
                    "date-parts": [
                        [
                            2023
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Graph-based event schema induction for information retrieval",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "2021-04-06 Assigned to INTERNATIONAL BUSINESS MACHINES CORPORATION reassignment INTERNATIONAL BUSINESS MACHINES CORPORATION ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS). Assignors: MAHINDRU, RUCHI, DENG, YU, WU, LINGFEI, HALDAR, RAJARSHI, KAYA, SINEM GUVEN2021-06-16 Assigned to THE BOARD OF TRUSTEES OF THE UNIVERSITY OF ILLINOIS reassignment THE BOARD OF TRUSTEES OF THE UNIVERSITY OF ILLINOIS ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS). Assignors: HOCKENMAIER, JULIA CONSTANZE",
                "DOI": "",
                "author": [
                    {
                        "family": "Haldar",
                        "given": "Rajarshi"
                    },
                    {
                        "family": "Deng",
                        "given": "Yu"
                    },
                    {
                        "family": "Wu",
                        "given": "Lingfei"
                    },
                    {
                        "family": "Mahindru",
                        "given": "Ruchi"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia Constanze"
                    },
                    {
                        "family": "Kaya",
                        "given": "Sinem Guven"
                    }
                ],
                "link": "https://patents.google.com/patent/US11615152/en",
                "issued": {
                    "date-parts": [
                        [
                            2023
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Feasibility analysis on the use of nlp-based schedule analytics for 4d project planning and controls",
                "container-title": "",
                "page": "42-50",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "4D (3D + time) building information modeling (BIM) brings important benefits to the practice of project planning and controls in construction. Despite well-documented benefits, the level of technical effort necessary to create 4D BIM by manually tying in BIM elements with schedule activities has been a significant barrier to its wider adoption. To address it, this paper explores the possibility of identifying <object, location, responsible party, means&method> in each schedule activity based on ASTM’s Uniformat classification and then automatically mapping it to the most relevant BIM elements in its corresponding work location. Specifically, the feasibility of training a transformer-based natural language processing model to infer Uniformat classification of a schedule activity is explored. Results from testing the proposed model on four real-word project schedules show the potential for a path forward toward automated 4D …",
                "DOI": "",
                "author": [
                    {
                        "family": "Jung",
                        "given": "Yoonhwa"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Golparvar-Fard",
                        "given": "Mani"
                    }
                ],
                "link": "https://ascelibrary.org/doi/abs/10.1061/9780784485224.006",
                "issued": {
                    "date-parts": [
                        [
                            2023
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Beast: Building an embodied action-prediction system with trajectory data",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We introduce our system BEAST (Building an Embodied Action-prediction System with Trajectory data) for interactive instruction-following within the Alexa Arena Platform. Our system leverages the abstraction of navigation provided by the Arena to decouple the language and vision predictions. This allows for greater simplicity within the system, and for rapid augmentation of the trajectory data-set and training for our text-only action prediction model. By creating a framework with a focus towards user experience our system is more robust to errors in predictions, and informative to the user.",
                "DOI": "",
                "author": [
                    {
                        "family": "Chakraborty",
                        "given": "Neeloy"
                    },
                    {
                        "family": "Sidhu",
                        "given": "Risham"
                    },
                    {
                        "family": "Abdullai",
                        "given": "Blerim"
                    },
                    {
                        "family": "Chen",
                        "given": "Haomiao"
                    },
                    {
                        "family": "Ravi",
                        "given": "Nikil"
                    },
                    {
                        "family": "Ankur",
                        "given": "Abhinav"
                    },
                    {
                        "family": "Prasad",
                        "given": "Devika"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Kingfisher",
                        "given": "Team"
                    }
                ],
                "link": "https://assets.amazon.science/3f/fa/439ec3a84ca7b0117088d5aad14d/revised-amazon-simbot-kingfisher-technical-report.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2023
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2022,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Multimedia generative script learning for task planning",
                "container-title": "arXiv preprint arXiv:2208.12306",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Goal-oriented generative script learning aims to generate subsequent steps to reach a particular goal, which is an essential task to assist robots or humans in performing stereotypical activities. An important aspect of this process is the ability to capture historical states visually, which provides detailed information that is not covered by text and will guide subsequent steps. Therefore, we propose a new task, Multimedia Generative Script Learning, to generate subsequent steps by tracking historical states in both text and vision modalities, as well as presenting the first benchmark containing 5,652 tasks and 79,089 multimedia steps. This task is challenging in three aspects: the multimedia challenge of capturing the visual states in images, the induction challenge of performing unseen tasks, and the diversity challenge of covering different information in individual steps. We propose to encode visual state changes through a selective multimedia encoder to address the multimedia challenge, transfer knowledge from previously observed tasks using a retrieval-augmented decoder to overcome the induction challenge, and further present distinct information at each step by optimizing a diversity-oriented contrastive learning objective. We define metrics to evaluate both generation and inductive quality. Experiment results demonstrate that our approach significantly outperforms strong baselines.",
                "DOI": "",
                "author": [
                    {
                        "family": "Wang",
                        "given": "Qingyun"
                    },
                    {
                        "family": "Li",
                        "given": "Manling"
                    },
                    {
                        "family": "Chan",
                        "given": "Hou Pong"
                    },
                    {
                        "family": "Huang",
                        "given": "Lifu"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Chowdhary",
                        "given": "Girish"
                    },
                    {
                        "family": "Ji",
                        "given": "Heng"
                    }
                ],
                "link": "https://arxiv.org/abs/2208.12306",
                "issued": {
                    "date-parts": [
                        [
                            2022
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Human-guided collaborative problem solving: A natural language based framework",
                "container-title": "arXiv preprint arXiv:2207.09566",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We consider the problem of human-machine collaborative problem solving as a planning task coupled with natural language communication. Our framework consists of three components -- a natural language engine that parses the language utterances to a formal representation and vice-versa, a concept learner that induces generalized concepts for plans based on limited interactions with the user, and an HTN planner that solves the task based on human interaction. We illustrate the ability of this framework to address the key challenges of collaborative problem solving by demonstrating it on a collaborative building task in a Minecraft-based blocksworld domain. The accompanied demo video is available at https://youtu.be/q1pWe4aahF0.",
                "DOI": "",
                "author": [
                    {
                        "family": "Kokel",
                        "given": "Harsha"
                    },
                    {
                        "family": "Das",
                        "given": "Mayukh"
                    },
                    {
                        "family": "Islam",
                        "given": "Rakibul"
                    },
                    {
                        "family": "Bonn",
                        "given": "Julia"
                    },
                    {
                        "family": "Cai",
                        "given": "Jon"
                    },
                    {
                        "family": "Dan",
                        "given": "Soham"
                    },
                    {
                        "family": "Narayan-Chen",
                        "given": "Anjali"
                    },
                    {
                        "family": "Jayannavar",
                        "given": "Prashant"
                    },
                    {
                        "family": "Doppa",
                        "given": "Janardhan Rao"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Natarajan",
                        "given": "Sriraam"
                    },
                    {
                        "family": "Palmer",
                        "given": "Martha"
                    },
                    {
                        "family": "Roth",
                        "given": "Dan"
                    }
                ],
                "link": "https://arxiv.org/abs/2207.09566",
                "issued": {
                    "date-parts": [
                        [
                            2022
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Learning and critiquing pairwise activity relationships for schedule quality control via deep learning-based natural language processing",
                "container-title": "Automation in Construction",
                "page": "104036",
                "volume": "134",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "In construction, schedule mistakes causing delays beyond substantial completion dates cost contractors expensive liquidated damages. Hence, several industry guidelines, such as the DCMA's 14 point assessment, define schedule quality and offer systematic methods for ensuring it. These guidelines list “logic” as an essential control metric, and they require planners to ensure their schedules are free of missing or wrong logical dependencies. Checking the logic requires extensive construction domain knowledge, and planners perform it entirely manually as there are no available software solutions that support it. This paper offers a novel machine learning-based solution that learns construction scheduling domain knowledge from existing records completely automatically and applies it to validate the logic in input schedules achieving an F1 score of 88.3%. Furthermore, we tailor our method to use the learned …",
                "DOI": "",
                "author": [
                    {
                        "family": "Amer",
                        "given": "Fouad"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Golparvar-Fard",
                        "given": "Mani"
                    }
                ],
                "link": "https://www.sciencedirect.com/science/article/pii/S0926580521004878",
                "issued": {
                    "date-parts": [
                        [
                            2022
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2021,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Multi-perspective, multi-task neural network model for matching text to program code",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Embodiments of the invention describe a computer-implemented method that includes receiving a query that includes a query sequence having query characters grouped into query words. A segment of program code is retrieved from a database for evaluation. The program code includes a program code sequence including program code characters grouped into program code words. The query sequence, the query word, the program code sequence, and the program code word are each converted to sequence and word representations. Query sequence-level features, query word-level features, program code sequence-level features, and program code word-level features are extracted from the sequence and word representation. Similarity between the query and the segment of program code is determined by applying a similarity metric technique to the query sequence-level features, the query word-level features, the program code sequence-level features, and the program code word-level features.",
                "DOI": "",
                "author": [
                    {
                        "family": "Xiong",
                        "given": "Jinjun"
                    },
                    {
                        "family": "Haldar",
                        "given": "Rajarshi"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia Constanze"
                    },
                    {
                        "family": "Wu",
                        "given": "Lingfei"
                    }
                ],
                "link": "https://experts.illinois.edu/en/publications/multi-perspective-multi-task-neural-network-model-for-matching-te",
                "issued": {
                    "date-parts": [
                        [
                            2021
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Multi-perspective, multi-task neural network model for matching text to program code",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Embodiments of the invention describe a computer-imple mented method that includes receiving a query that includes a query sequence having query characters grouped into query words. A segment of program code is retrieved from a database for evaluation. The program code includes a program code sequence including program code characters grouped into program code words. The query sequence, the query word, the program code sequence, and the program code word are each converted to sequence and word repre sentations. Query sequence-level features, query word-level features, program code sequence-level features, and pro gram code word-level features are extracted from the sequence and word representation. Similarity between the query and the segment of program code is determined by applying a similarity metric technique to the query sequence-level features, the query word-level fea …",
                "DOI": "",
                "author": [
                    {
                        "family": "Wu",
                        "given": "Lingfei"
                    },
                    {
                        "family": "Xiong",
                        "given": "JinJun"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia Constanze"
                    },
                    {
                        "family": "Haldar",
                        "given": "Rajarshi"
                    }
                ],
                "link": "https://patents.google.com/patent/US11132512B2/en",
                "issued": {
                    "date-parts": [
                        [
                            2021
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "HySPA: Hybrid span generation for scalable text-to-graph extraction",
                "container-title": "arXiv preprint arXiv:2106.15838",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Text-to-Graph extraction aims to automatically extract information graphs consisting of mentions and types from natural language texts. Existing approaches, such as table filling and pairwise scoring, have shown impressive performance on various information extraction tasks, but they are difficult to scale to datasets with longer input texts because of their second-order space/time complexities with respect to the input length. In this work, we propose a Hybrid Span Generator (HySPA) that invertibly maps the information graph to an alternating sequence of nodes and edge types, and directly generates such sequences via a hybrid span decoder which can decode both the spans and the types recurrently in linear time and space complexities. Extensive experiments on the ACE05 dataset show that our approach also significantly outperforms state-of-the-art on the joint entity and relation extraction task.",
                "DOI": "",
                "author": [
                    {
                        "family": "Ren",
                        "given": "Liliang"
                    },
                    {
                        "family": "Sun",
                        "given": "Chenkai"
                    },
                    {
                        "family": "Ji",
                        "given": "Heng"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2106.15838",
                "issued": {
                    "date-parts": [
                        [
                            2021
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2020,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "University of Illinois submission to the SIGMORPHON 2020 shared task 0: Typologically diverse morphological inflection",
                "container-title": "",
                "page": "137-145",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "The objective of this shared task is to produce an inflected form of a word, given its lemma and a set of tags describing the attributes of the desired form. In this paper, we describe a transformer-based model that uses a bidirectional decoder to perform this task, and evaluate its performance on the 90 languages and 18 language families used in this task.",
                "DOI": "",
                "author": [
                    {
                        "family": "Canby",
                        "given": "Marc"
                    },
                    {
                        "family": "Karipbayeva",
                        "given": "Aidana"
                    },
                    {
                        "family": "Lunt",
                        "given": "Bryan"
                    },
                    {
                        "family": "Mozaffari",
                        "given": "Sahand"
                    },
                    {
                        "family": "Yoder",
                        "given": "Charlotte"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/2020.sigmorphon-1.15/",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Learning to execute instructions in a Minecraft dialogue",
                "container-title": "",
                "page": "2589-2602",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "The Minecraft Collaborative Building Task is a two-player game in which an Architect (A) instructs a Builder (B) to construct a target structure in a simulated Blocks World Environment. We define the subtask of predicting correct action sequences (block placements and removals) in a given game context, and show that capturing B’s past actions as well as B’s perspective leads to a significant improvement in performance on this challenging language understanding problem.",
                "DOI": "",
                "author": [
                    {
                        "family": "Jayannavar",
                        "given": "Prashant"
                    },
                    {
                        "family": "Narayan-Chen",
                        "given": "Anjali"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/2020.acl-main.232/",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "A multi-perspective architecture for semantic code search",
                "container-title": "arXiv preprint arXiv:2005.06980",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "The ability to match pieces of code to their corresponding natural language descriptions and vice versa is fundamental for natural language search interfaces to software repositories. In this paper, we propose a novel multi-perspective cross-lingual neural framework for code--text matching, inspired in part by a previous model for monolingual text-to-text matching, to capture both global and local similarities. Our experiments on the CoNaLa dataset show that our proposed model yields better performance on this cross-lingual text-to-code matching task than previous approaches that map code and text to a single joint embedding space.",
                "DOI": "",
                "author": [
                    {
                        "family": "Haldar",
                        "given": "Rajarshi"
                    },
                    {
                        "family": "Wu",
                        "given": "Lingfei"
                    },
                    {
                        "family": "Xiong",
                        "given": "Jinjun"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/2005.06980",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2019,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Phrase Grounding by Soft-Label Chain Conditional Random Field",
                "container-title": "",
                "page": "5112--5122",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "The phrase grounding task aims to ground each entity mention in a given caption of an image to a corresponding region in that image. Although there are clear dependencies between how different mentions of the same caption should be grounded, previous structured prediction methods that aim to capture such dependencies need to resort to approximate inference or non-differentiable losses. In this paper, we formulate phrase grounding as a sequence labeling task where we treat candidate regions as potential labels, and use neural chain Conditional Random Fields (CRFs) to model dependencies among regions for adjacent mentions. In contrast to standard sequence labeling tasks, the phrase grounding task is defined such that there may be multiple correct candidate regions. To address this multiplicity of gold labels, we define so-called Soft-Label Chain CRFs, and present an algorithm that enables convenient end-to-end training. Our method establishes a new state-of-the-art on phrase grounding on the Flickr30k Entities dataset. Analysis shows that our model benefits both from the entity dependencies captured by the CRF and from the soft-label training regime. Our code is available at \\url{github.com/liujch1998/SoftLabelCCRF}",
                "DOI": "",
                "author": [
                    {
                        "family": "Liu",
                        "given": "Jiacheng"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/1909.00301",
                "issued": {
                    "date-parts": [
                        [
                            2019
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Collaborative dialogue in Minecraft",
                "container-title": "",
                "page": "5405-5415",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We wish to develop interactive agents that can communicate with humans to collaboratively solve tasks in grounded scenarios. Since computer games allow us to simulate such tasks without the need for physical robots, we define a Minecraft-based collaborative building task in which one player (A, the Architect) is shown a target structure and needs to instruct the other player (B, the Builder) to build this structure. Both players interact via a chat interface. A can observe B but cannot place blocks. We present the Minecraft Dialogue Corpus, a collection of 509 conversations and game logs. As a first step towards our goal of developing fully interactive agents for this task, we consider the subtask of Architect utterance generation, and show how challenging it is.",
                "DOI": "",
                "author": [
                    {
                        "family": "Narayan-Chen",
                        "given": "Anjali"
                    },
                    {
                        "family": "Jayannavar",
                        "given": "Prashant"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/P19-1537/",
                "issued": {
                    "date-parts": [
                        [
                            2019
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Virtual world context encoding for grounded dialogue in minecraft",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Our research aims to develop agents that can communicate with each other using natural language (eg to give and execute instructions) in a 3D environment. We use Minecraft, a game in which players can explore a 3D environment and build structures out of blocks. In the Minecraft Collaborative Building Task, an Architect (A) has to instruct a Builder (B) via chat to build a copy of a Target structure given to A. Throughout the game, A and B communicate back and forth via chat, but while A can observe B, only B can place blocks.We designed and implemented a convolutional neural network (CNN) to recognize shapes in Minecraft’s virtual 3D environment. We have begun to use the output of this CNN as input to models that generate utterances for the Architect or Builder agents, and will be incorporating it into models that predict the Builder’s next block placement actions.",
                "DOI": "",
                "author": [
                    {
                        "family": "Lambert",
                        "given": "Charlotte"
                    },
                    {
                        "family": "Cordes",
                        "given": "Ariel"
                    },
                    {
                        "family": "Kaplan",
                        "given": "Elli"
                    },
                    {
                        "family": "Jayannavar",
                        "given": "Prashant"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://drive.google.com/file/d/1Cbc0rmz7vN92TFOEC6q5Y4Gc1VVu3Pck/view",
                "issued": {
                    "date-parts": [
                        [
                            2019
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2018,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Preface by the program committee co-chairs",
                "container-title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018",
                "page": "viii-ix",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Preface by the program committee co-chairs — University of Illinois Urbana-Champaign Skip \nto main navigation Skip to search Skip to main content University of Illinois Urbana-Champaign \nHome University of Illinois Urbana-Champaign Logo LOGIN & Help Home Profiles Research \nunits Research & Scholarship Datasets Honors Press/Media Activities Search by expertise, \nname or affiliation Preface by the program committee co-chairs David Chiang, Julia \nHockenmaier, Jun'ichi Tsujii Computer Science Coordinated Science Lab Linguistics National \nCenter for Supercomputing Applications (NCSA) Research output: Contribution to journal › \nEditorial › peer-review Overview Original language English (US) Pages (from-to) viii-ix Journal \nProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, \nEMNLP 2018 State Published - 2018 Event 2018 Conference on Empirical Methods in …",
                "DOI": "",
                "author": [
                    {
                        "family": "Chiang",
                        "given": "David"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Tsujii",
                        "given": "Jun'ichi"
                    }
                ],
                "link": "https://experts.illinois.edu/en/publications/preface-by-the-program-committee-co-chairs-2",
                "issued": {
                    "date-parts": [
                        [
                            2018
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Welcome to EMNLP 2018 in Brussels, Belgium! I hope that EMNLP 2018 will be a memorable experience filled with exciting research presentations, outstanding keynote speakers, and many stimulating conversations with colleagues and friends, both old and new. In the evenings, I hope that you will explore the wonderful city of Brussels! Admire the historic buildings, visit great museums, and enjoy the Belgian cuisine.EMNLP 2018 will have an extensive technical program that includes 14 workshops, 6 tutorials, 3 invited speakers, 351 long paper presentations, 198 short paper presentations, 10 TACL paper presentations, and 29 demos. I want to give special thanks to the Program Co-Chairs: David Chiang, Julia Hockenmaier, and Jun’ichi Tsujii. EMNLP 2018 received a record-breaking 2,231 valid submissions, a 48% increase over EMNLP 2017! Despite the massive volume of submissions, the PC chairs put tremendous care into every decision, big and small, and gracefully handled numerous inquiries and requests. Their commitment to a high-quality program was inspiring. Of course, the PC Chairs did not handle the workload alone: we all owe an enormous debt of gratitude to the 60 Area Chairs and 1,436 reviewers (yes, 1,400+ reviewers!) who took on the critical responsibilities of reviewing paper submissions and providing feedback to the program chairs. Thank you all!",
                "DOI": "",
                "author": [
                    {
                        "family": "Riloff",
                        "given": "Ellen"
                    },
                    {
                        "family": "Chiang",
                        "given": "David"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Tsujii",
                        "given": "Jun’ichi"
                    }
                ],
                "link": "https://aclanthology.org/D18-1000.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2018
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2017,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Natural language inference from multiple premises",
                "container-title": "",
                "page": "721--730",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We define a novel textual entailment task that requires inference over multiple premise sentences. We present a new dataset for this task that minimizes trivial lexical inferences, emphasizes knowledge of everyday events, and presents a more challenging setting for textual entailment. We evaluate several strong neural baselines and analyze how the multiple premise task differs from standard textual entailment.",
                "DOI": "",
                "author": [
                    {
                        "family": "Lai",
                        "given": "Alice"
                    },
                    {
                        "family": "Bisk",
                        "given": "Yonatan"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://arxiv.org/abs/1710.02925",
                "issued": {
                    "date-parts": [
                        [
                            2017
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Towards problem solving agents that communicate and learn",
                "container-title": "",
                "page": "95-103",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Agents that communicate back and forth with humans to help them execute non-linguistic tasks are a long sought goal of AI. These agents need to translate between utterances and actionable meaning representations that can be interpreted by task-specific problem solvers in a context-dependent manner. They should also be able to learn such actionable interpretations for new predicates on the fly. We define an agent architecture for this scenario and present a series of experiments in the Blocks World domain that illustrate how our architecture supports language learning and problem solving in this domain.",
                "DOI": "",
                "author": [
                    {
                        "family": "Narayan-Chen",
                        "given": "Anjali"
                    },
                    {
                        "family": "Graber",
                        "given": "Colin"
                    },
                    {
                        "family": "Das",
                        "given": "Mayukh"
                    },
                    {
                        "family": "Islam",
                        "given": "Md Rakibul"
                    },
                    {
                        "family": "Dan",
                        "given": "Soham"
                    },
                    {
                        "family": "Natarajan",
                        "given": "Sriraam"
                    },
                    {
                        "family": "Doppa",
                        "given": "Janardhan Rao"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Palmer",
                        "given": "Martha"
                    },
                    {
                        "family": "Roth",
                        "given": "Dan"
                    }
                ],
                "link": "https://aclanthology.org/W17-2812/",
                "issued": {
                    "date-parts": [
                        [
                            2017
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Learning to predict denotational probabilities for modeling entailment",
                "container-title": "",
                "page": "721-730",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We propose a framework that captures the denotational probabilities of words and phrases by embedding them in a vector space, and present a method to induce such an embedding from a dataset of denotational probabilities. We show that our model successfully predicts denotational probabilities for unseen phrases, and that its predictions are useful for textual entailment datasets such as SICK and SNLI.",
                "DOI": "",
                "author": [
                    {
                        "family": "Lai",
                        "given": "Alice"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/E17-1068/",
                "issued": {
                    "date-parts": [
                        [
                            2017
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Phrase localization and visual relationship detection with comprehensive image-language cues",
                "container-title": "",
                "page": "1928-1937",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper presents a framework for localization or grounding of phrases in images using a large collection of linguistic and visual cues. We model the appearance, size, and position of entity bounding boxes, adjectives that contain attribute information, and spatial relationships between pairs of entities connected by verbs or prepositions. Special attention is given to relationships between people and clothing or body part mentions, as they are useful for distinguishing individuals. We automatically learn weights for combining these cues and at test time, perform joint inference over all phrases in a caption. The resulting system produces state of the art performance on phrase localization on the Flickr30k Entities dataset and visual relationship detection on the Stanford VRD dataset.",
                "DOI": "",
                "author": [
                    {
                        "family": "Plummer",
                        "given": "Bryan A"
                    },
                    {
                        "family": "Mallya",
                        "given": "Arun"
                    },
                    {
                        "family": "Cervantes",
                        "given": "Christopher M"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Lazebnik",
                        "given": "Svetlana"
                    }
                ],
                "link": "http://openaccess.thecvf.com/content_iccv_2017/html/Plummer_Phrase_Localization_and_ICCV_2017_paper.html",
                "issued": {
                    "date-parts": [
                        [
                            2017
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2016,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Evaluating induced CCG parsers on grounded semantic parsing",
                "container-title": "arXiv preprint arXiv:1609.09405",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We compare the effectiveness of four different syntactic CCG parsers for a semantic slot-filling task to explore how much syntactic supervision is required for downstream semantic analysis. This extrinsic, task-based evaluation provides a unique window to explore the strengths and weaknesses of semantics captured by unsupervised grammar induction systems. We release a new Freebase semantic parsing dataset called SPADES (Semantic PArsing of DEclarative Sentences) containing 93K cloze-style questions paired with answers. We evaluate all our models on this dataset. Our code and data are available at https://github.com/sivareddyg/graph-parser.",
                "DOI": "",
                "author": [
                    {
                        "family": "Bisk",
                        "given": "Yonatan"
                    },
                    {
                        "family": "Reddy",
                        "given": "Siva"
                    },
                    {
                        "family": "Blitzer",
                        "given": "John"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    }
                ],
                "link": "https://arxiv.org/abs/1609.09405",
                "issued": {
                    "date-parts": [
                        [
                            2016
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Focused evaluation for image description with binary forced-choice tasks",
                "container-title": "",
                "page": "19-28",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Current evaluation metrics for image description may be too coarse. We therefore propose a series of binary forced-choice tasks that each focus on a different aspect of the captions. We evaluate a number of different off-the-shelf image description systems. Our results indicate strengths and shortcomings of both generation and ranking based approaches.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hodosh",
                        "given": "Micah"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/W16-3203.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2016
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2015,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Probing the linguistic strengths and limitations of unsupervised grammar induction",
                "container-title": "",
                "page": "1395-1404",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Work in grammar induction should help shed light on the amount of syntactic structure that is discoverable from raw word or tag sequences. But since most current grammar induction algorithms produce unlabeled dependencies, it is difficult to analyze what types of constructions these algorithms can or cannot capture, and, therefore, to identify where additional supervision may be necessary. This paper provides an in-depth analysis of the errors made by unsupervised CCG parsers by evaluating them against the labeled dependencies in CCGbank, hinting at new research directions necessary for progress in grammar induction.",
                "DOI": "",
                "author": [
                    {
                        "family": "Bisk",
                        "given": "Yonatan"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/P15-1135.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2015
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Labeled grammar induction with minimal supervision",
                "container-title": "",
                "page": "870-876",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Nearly all work in unsupervised grammar induction aims to induce unlabeled dependency trees from gold part-of-speechtagged text. These clean linguistic classes provide a very important, though unrealistic, inductive bias. Conversely, induced clusters are very noisy. We show here, for the first time, that very limited human supervision (three frequent words per cluster) may be required to induce labeled dependencies from automatically induced word clusters.",
                "DOI": "",
                "author": [
                    {
                        "family": "Bisk",
                        "given": "Yonatan"
                    },
                    {
                        "family": "Christodoulopoulos",
                        "given": "Christos"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/P15-2143.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2015
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models",
                "container-title": "",
                "page": "2641-2649",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "The Flickr30k dataset has become a standard benchmark for sentence-based image description. This paper presents Flickr30k Entities, which augments the 158k captions from Flickr30k with 244k coreference chains linking mentions of the same entities in images, as well as 276k manually annotated bounding boxes corresponding to each entity. Such annotation is essential for continued progress in automatic image description and grounded language understanding. We present experiments demonstrating the usefulness of our annotations for text-to-image reference resolution, or the task of localizing textual entity mentions in an image, and for bidirectional image-sentence retrieval. These experiments confirm that we can further improve the accuracy of state-of-the-art retrieval methods by training with explicit region-to-phrase correspondence, but at the same time, they show that accurately inferring this correspondence given an image and a caption remains really challenging.",
                "DOI": "",
                "author": [
                    {
                        "family": "Plummer",
                        "given": "Bryan A"
                    },
                    {
                        "family": "Wang",
                        "given": "Liwei"
                    },
                    {
                        "family": "Cervantes",
                        "given": "Chris M"
                    },
                    {
                        "family": "Caicedo",
                        "given": "Juan C"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Lazebnik",
                        "given": "Svetlana"
                    }
                ],
                "link": "http://openaccess.thecvf.com/content_iccv_2015/html/Plummer_Flickr30k_Entities_Collecting_ICCV_2015_paper.html",
                "issued": {
                    "date-parts": [
                        [
                            2015
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2014,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Illinois-lh: A denotational and distributional approach to semantics",
                "container-title": "",
                "page": "329-334",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper describes and analyzes our SemEval 2014 Task 1 system. Its features are based on distributional and denotational similarities; word alignment; negation; and hypernym/hyponym, synonym, and antonym relations.",
                "DOI": "",
                "author": [
                    {
                        "family": "Lai",
                        "given": "Alice"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/S14-2055.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2014
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
                "container-title": "Transactions of the Association for Computational Linguistics (TACL)",
                "page": "67-78",
                "volume": "2",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We propose to use the visual denotations of                     linguistic expressions (i.e. the set of images they describe) to define novel                         denotational similarity metrics, which we show                     to be at least as beneficial as distributional similarities for two tasks that                     require semantic inference. To compute these denotational similarities, we                     construct a denotation graph, i.e. a subsumption                     hierarchy over constituents and their denotations, based on a large corpus of                     30K images and 150K descriptive captions.",
                "DOI": "",
                "author": [
                    {
                        "family": "Young",
                        "given": "Peter"
                    },
                    {
                        "family": "Lai",
                        "given": "Alice"
                    },
                    {
                        "family": "Hodosh",
                        "given": "Micah"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://direct.mit.edu/tacl/article-abstract/doi/10.1162/tacl_a_00166/43313",
                "issued": {
                    "date-parts": [
                        [
                            2014
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Improving image-sentence embeddings using large weakly annotated photo collections",
                "container-title": "",
                "page": "529-545",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper studies the problem of associating images with descriptive sentences by embedding them in a common latent space. We are interested in learning such embeddings from hundreds of thousands or millions of examples. Unfortunately, it is prohibitively expensive to fully annotate this many training images with ground-truth sentences. Instead, we ask whether we can learn better image-sentence embeddings by augmenting small fully annotated training sets with millions of images that have weak and noisy annotations (titles, tags, or descriptions). After investigating several state-of-the-art scalable embedding methods, we introduce a new algorithm called Stacked Auxiliary Embedding that can successfully transfer knowledge from millions of weakly annotated images to improve the accuracy of retrieval-based image description.",
                "DOI": "",
                "author": [
                    {
                        "family": "Gong",
                        "given": "Yunchao"
                    },
                    {
                        "family": "Wang",
                        "given": "Liwei"
                    },
                    {
                        "family": "Hodosh",
                        "given": "Micah"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Lazebnik",
                        "given": "Svetlana"
                    }
                ],
                "link": "https://link.springer.com/chapter/10.1007/978-3-319-10593-2_35",
                "issued": {
                    "date-parts": [
                        [
                            2014
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2013,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Structural parse tree features for text representation",
                "container-title": "",
                "page": "9-16",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We propose and study novel text representation features created from parse tree structures. Unlike the traditional parse tree features which include all the attached syntactic categories to capture linguistic properties of text, the new features are solely or primarily defined based on the tree structure, and thus better reflect the pure structural properties of parse trees. We hypothesize that these new complex structural features capture an orthogonal perspective of text even compared to advanced syntactic ones. Evaluation based on three different text categorization tasks (i.e., nationality detection, essay scoring, and sentiment analysis) shows that the proposed new tree structure features complement the existing ones to enrich text representation. Experiment results further show that a combination of the proposed new structure features with word n-grams can improve F 1  score and classification accuracy.",
                "DOI": "",
                "author": [
                    {
                        "family": "Massung",
                        "given": "Sean"
                    },
                    {
                        "family": "Zhai",
                        "given": "ChengXiang"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://ieeexplore.ieee.org/abstract/document/6693488/",
                "issued": {
                    "date-parts": [
                        [
                            2013
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Framing image description as a ranking task: Data, models and evaluation metrics",
                "container-title": "Journal of Artificial Intelligence Research",
                "page": "853-899",
                "volume": "47",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "The ability to associate images with natural language sentences that describe what is depicted in them is a hallmark of image understanding, and a prerequisite for applications such as sentence-based image search. In analogy to image search, we propose to frame sentence-based image annotation as the task of ranking a given pool of captions. We introduce a new benchmark collection for sentence-based image description and search, consisting of 8,000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events. We introduce a number of systems that perform quite well on this task, even though they are only based on features that can be obtained with minimal supervision. Our results clearly indicate the importance of training on multiple captions per image, and of capturing syntactic (word order-based) and semantic features of these captions. We also perform an in-depth comparison of human and automatic evaluation metrics for this task, and propose strategies for collecting human judgments cheaply and on a very large scale, allowing us to augment our collection with additional relevance judgments of which captions describe which image. Our analysis shows that metrics that consider the ranked list of results for each query image or sentence are significantly more robust than metrics that are based on a single response per query. Moreover, our study suggests that the evaluation of ranking-based image description systems may be fully automated.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hodosh",
                        "given": "Micah"
                    },
                    {
                        "family": "Young",
                        "given": "Peter"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://www.jair.org/index.php/jair/article/view/10833",
                "issued": {
                    "date-parts": [
                        [
                            2013
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Proceedings of the Seventeenth Conference on Computational Natural Language Learning",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "The 2013 Conference on Computational Natural Language Learning is the seventeenth in the series of annual meetings organized by SIGNLL, the ACL special interest group on natural language learning. CONLL-2013 will be held in Sofia, Bulgaria, Europe, August 8-9, 2013, in conjunction with ACL 2013.For our special focus this year in the main session of CoNLL, we invited papers relating to compositional semantics. We received 107 submissions on this and other relevant topics, of which 7 were eventually withdrawn. Of the remaining 100 papers, 25 were selected to appear in the conference program as oral presentation. All accepted papers appear here in the proceedings. Each accepted paper was allowed eight content pages plus two pages containing only bibliographic references.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Riedel",
                        "given": "Sebastian"
                    }
                ],
                "link": "https://aclanthology.org/W13-3500.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2013
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Proceedings of the Workshop on Vision and Natural Language Processing",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "There is an increasing amount of research at the interfaces of speech and language processing and computer vision, computer graphics, robotics and information retrieval which aims to develop systems that automatically generate descriptions of images or videos, or generate images based on natural language descriptions, acquire and understand language in a perceptually grounded, visual context, or perform language-based image search.Since the main purpose of this workshop is to bring researchers from these communities together, the workshop will mostly consist of invited talks, both by NLP and computer vision students who are working in the area, as well as by established researchers from academia and industry.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Berg",
                        "given": "Tamara"
                    }
                ],
                "link": "https://aclanthology.org/W13-1300.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2013
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Proceedings of the 2013 NAACL HLT Student Research Workshop",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This year, we have two different kinds of paper: research papers and thesis proposals. Thesis proposals are intended for advanced students who have decided on a thesis topic and wish to get feedback on their proposal and broader ideas for their continuing work, while research papers can describe completed work or work in progress with preliminary results.All the papers will be presented in the main conference poster session, giving the opportunity for students to interact and present their work to a large and diverse audience. In addition, we have a separate session for the student papers on the first day of workshops (after the main conference). During this session, students will present their papers and receive feedback from mentors. The mentors are experienced researchers who will prepare in-depth comments and questions in advance of the presentation. Each accepted paper is assigned a mentor. The separate session is newly introduced this year and differs from recent NAACL student workshops where student talks were during the main conference sessions or the papers were presented as posters only. We expect that the focused workshop will provide a greater opportunity for receive feedback from mentors, and also allow the students to network and socialize with other student participants.",
                "DOI": "",
                "author": [
                    {
                        "family": "Louis",
                        "given": "Annie"
                    },
                    {
                        "family": "Socher",
                        "given": "Richard"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Ringger",
                        "given": "Eric"
                    }
                ],
                "link": "https://aclanthology.org/N13-2000.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2013
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "An HDP Model for Inducing Combinatory Categorial Grammars",
                "container-title": "Transactions of the Association for Computational Linguistics (TACL)",
                "page": "75-88",
                "volume": "1",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We introduce a novel nonparametric Bayesian model for the induction of                     Combinatory Categorial Grammars from POS-tagged text. It achieves state of the                     art performance on a number of languages, and induces linguistically plausible                     lexicons.",
                "DOI": "",
                "author": [
                    {
                        "family": "Bisk",
                        "given": "Yonatan"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://direct.mit.edu/tacl/article-abstract/doi/10.1162/tacl_a_00211/43196",
                "issued": {
                    "date-parts": [
                        [
                            2013
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Sentence-based image description with scalable, explicit models",
                "container-title": "",
                "page": "294-300",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Associating photographs with complete sentences that describe what is depicted in them is a challenging problem. This paper examines how an approach that is inspired by image tagging techniques which can scale to very large data sets performs on this much harder task, and examines some of the linguistic difficulties that this bag-of-words model faces.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hodosh",
                        "given": "Micah"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2013/W06/html/Hodosh_Sentence-Based_Image_Description_2013_CVPR_paper.html",
                "issued": {
                    "date-parts": [
                        [
                            2013
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2012,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Etm: Entity topic models for mining documents associated with entities",
                "container-title": "",
                "page": "349-358",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Topic models, which factor each document into different topics and represent each topic as a distribution of terms, have been widely and successfully used to better understand collections of text documents. However, documents are also associated with further information, such as the set of real-world entities mentioned in them. For example, news articles are usually related to several people, organizations, countries or locations. Since those associated entities carry rich information, it is highly desirable to build more expressive, entity-based topic models, which can capture the term distributions for each topic, each entity, as well as each topic-entity pair. In this paper, we therefore introduce a novel Entity Topic Model (ETM) for documents that are associated with a set of entities. ETM not only models the generative process of a term given its topic and entity information, but also models the correlation of entity term …",
                "DOI": "",
                "author": [
                    {
                        "family": "Kim",
                        "given": "Hyungsul"
                    },
                    {
                        "family": "Sun",
                        "given": "Yizhou"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Han",
                        "given": "Jiawei"
                    }
                ],
                "link": "https://ieeexplore.ieee.org/abstract/document/6413746/",
                "issued": {
                    "date-parts": [
                        [
                            2012
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Beefmoves: dissemination, diversity, and dynamics of English borrowings in a German hip hop forum",
                "container-title": "",
                "page": "135-139",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We investigate how novel English-derived words (anglicisms) are used in a Germanlanguage Internet hip hop forum, and what factors contribute to their uptake.",
                "DOI": "",
                "author": [
                    {
                        "family": "Garley",
                        "given": "Matt"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/P12-2027.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2012
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Combinatory Categorial Grammars for Robust Natural Language Processing",
                "container-title": "University of Edinburgh",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "• We shall see that, for certain categories of parser error, up to half the error rate is due to unseen grammatical event types (such as lexical entries), and up to half is due to unseen model tokens for seen types (such as head word dependencies).",
                "DOI": "",
                "author": [
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    },
                    {
                        "family": "Curran",
                        "given": "James"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Kwiatkowski",
                        "given": "Tom"
                    },
                    {
                        "family": "Lewis",
                        "given": "Mike"
                    },
                    {
                        "family": "Park",
                        "given": "Jong"
                    },
                    {
                        "family": "Thomforde",
                        "given": "Emily"
                    },
                    {
                        "family": "Boonkwan",
                        "given": "Prachya"
                    },
                    {
                        "family": "Copolla",
                        "given": "Greg"
                    },
                    {
                        "family": "Goldwater",
                        "given": "Sharon"
                    }
                ],
                "link": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=520b3b44f51ceb123f0fbc63d2b821798c8052ff",
                "issued": {
                    "date-parts": [
                        [
                            2012
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Induction of linguistic structure with combinatory categorial grammars",
                "container-title": "",
                "page": "90-95",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Our system consists of a simple, EM-based induction algorithm (Bisk and Hockenmaier, 2012), which induces a language-specific Combinatory Categorial grammar (CCG) and lexicon based on a small number of linguistic principles, eg that verbs may be the roots of sentences and can take nouns as arguments.",
                "DOI": "",
                "author": [
                    {
                        "family": "Bisk",
                        "given": "Yonatan"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/W12-1912.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2012
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Simple robust grammar induction with combinatory categorial grammars",
                "container-title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "page": "1643-1649",
                "volume": "26",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We present a simple EM-based grammar induction algorithm for Combinatory Categorial Grammar (CCG) that achieves state-of-the-art performance by relying on a minimal number of very general linguistic principles. Unlike previous work on unsupervised parsing with CCGs, our approach has no prior language-specific knowledge, and discovers all categories automatically. Additionally, unlike other approaches, our grammar remains robust when parsing longer sentences, performing as well as or better than other systems. We believe this is a natural result of using an expressive grammar formalism with an extended domain of locality.",
                "DOI": "",
                "author": [
                    {
                        "family": "Bisk",
                        "given": "Yonatan"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://ojs.aaai.org/index.php/AAAI/article/view/8355",
                "issued": {
                    "date-parts": [
                        [
                            2012
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2011,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Lecture 6: Topic Models (Latent Dirichlet Allocation)",
                "container-title": "Published online at cs. illinois. edu/class/sp10/cs598jhm/.../Lecture06HO. pdf. Last visited November",
                "page": "",
                "volume": "1",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Lecture 6: Topic Models (Latent Dirichlet Allocation) Page 1 CS598JHM: Advanced NLP (Spring \nʼ10) Julia Hockenmaier juliahmr@illinois.edu 3324 Siebel Center http://www.cs.uiuc.edu/class/sp10/cs598jhm \nLecture 6: Topic Models (Latent Dirichlet Allocation) Page 2 CS598JHM: Advanced NLP \nTopic models Motivating questions: -What are the topics that a document is about? -Given \none document, can we find other documents about the same topics? -How do topics in a \nfield change over time? A hierarchical Bayesian approach: -Assume each document defines \na distribution over (hidden) topics -Assume each topic defines a distribution over words \n-The posterior probability of these latent variables given a document collection determines \na hidden decomposition of the collection into topics. 2 Page 3 CS598JHM: Advanced \nNLP References D. Blei, A. Ng, and M. Jordan. Latent Dirichlet allocation. Journal of …",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://courses.grainger.illinois.edu/cs598jhm/sp2010/Slides/Lecture06.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2011
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Reasoning about robocup soccer narratives",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper presents an approach for learning to translate simple narratives, i.e., texts (sequences of sentences) describing dynamic systems, into coherent sequences of events without the need for labeled training data. Our approach incorporates domain knowledge in the form of preconditions and effects of events, and we show that it outperforms state-of-the-art supervised learning systems on the task of reconstructing RoboCup soccer games from their commentaries.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hajishirzi",
                        "given": "Hannaneh"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Mueller",
                        "given": "Erik T"
                    },
                    {
                        "family": "Amir",
                        "given": "Eyal"
                    }
                ],
                "link": "https://arxiv.org/abs/1202.3728",
                "issued": {
                    "date-parts": [
                        [
                            2011
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2010,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Normal-form parsing for Combinatory Categorial Grammars with generalized composition and type-raising",
                "container-title": "",
                "page": "465-473",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We propose and implement a modification of the Eisner (1996) normal form to account for generalized composition of bounded degree, and an extension to deal with grammatical type-raising.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Bisk",
                        "given": "Yonatan"
                    }
                ],
                "link": "https://aclanthology.org/C10-1053.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2010
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Shallow information extraction from medical forum data",
                "container-title": "",
                "page": "1158-1166",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We study a novel shallow information extraction problem that involves extracting sentences of a given set of topic categories from medical forum data. Given a corpus of medical forum documents, our goal is to extract two related types of sentences that describe a biomedical case (ie, medical problem descriptions and medical treatment descriptions). Such an extraction task directly generates medical case descriptions that can be useful in many applications. We solve the problem using two popular machine learning methods Support Vector Machines (SVM) and Conditional Random Fields (CRF). We propose novel features to improve the accuracy of extraction. Experiment results show that we can obtain an accuracy of up to 75%.",
                "DOI": "",
                "author": [
                    {
                        "family": "Sondhi",
                        "given": "Parikshit"
                    },
                    {
                        "family": "Gupta",
                        "given": "Manish"
                    },
                    {
                        "family": "Zhai",
                        "given": "ChengXiang"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/C10-2133.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2010
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Citation author topic model in expert search",
                "container-title": "",
                "page": "1265-1273",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper proposes a novel topic model, Citation-Author-Topic (CAT) model that addresses a semantic search task we define as expert search–given a research area as a query, it returns names of experts in this area. For example, Michael Collins would be one of the top names retrieved given the query Syntactic Parsing.Our contribution in this paper is two-fold. First, we model the cited author information together with words and paper authors. Such extra contextual information directly models linkage among authors and enhances the author-topic association, thus produces more coherent author-topic distribution. Second, we provide a preliminary solution to the task of expert search when the learning repository contains exclusively research related documents authored by the experts. When compared with a previous proposed model (Johri et al., 2010), the proposed model produces high quality author topic linkage and achieves over 33% error reduction evaluated by the standard MAP measurement.",
                "DOI": "",
                "author": [
                    {
                        "family": "Tu",
                        "given": "Yuancheng"
                    },
                    {
                        "family": "Johri",
                        "given": "Nikhil"
                    },
                    {
                        "family": "Roth",
                        "given": "Dan"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/C10-2145.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2010
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Cross-caption coreference resolution for automatic image understanding",
                "container-title": "CoNLL-2010",
                "page": "162",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Recent work in computer vision has aimed to associate image regions with keywords describing the depicted entities, but actual image ‘understanding’would also require identifying their attributes, relations and activities. Since this information cannot be conveyed by simple keywords, we have collected a corpus of “action” photos each associated with five descriptive captions. In order to obtain a consistent semantic representation for each image, we need to first identify which NPs refer to the same entities. We present three hierarchical Bayesian models for cross-caption coreference resolution. We have also created a simple ontology of entity classes that appear in images and evaluate how well these can be recovered.",
                "DOI": "",
                "author": [
                    {
                        "family": "Rashtchian",
                        "given": "Micah Hodosh Peter Young Cyrus"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://www.academia.edu/download/39837878/Syntactic_and_semantic_structure_for_opi20151109-30183-1yw7r0u.pdf#page=178",
                "issued": {
                    "date-parts": [
                        [
                            2010
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Wide-coverage NLP with Linguistically Expressive Grammars",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "In recent years, there has been a lot of research on wide-coverage statistical natural language processing with linguistically expressive grammars such as Combinatory Categorial Grammars (CCG), Head-driven Phrase-Structure Grammars (HPSG), Lexical-Functional Grammars (LFG) and Tree-Adjoining Grammars (TAG). But although many young researchers in natural language processing are very well trained in machine learning and statistical methods, they often lack the necessary background to understand the linguistic motivation behind these formalisms. Furthermore, in many linguistics departments, syntax is still taught from a purely Chomskian perspective. Additionally, research on these formalisms often takes place within tightly-knit, formalismspecific subcommunities. It is therefore often difficult for outsiders as well as experts to grasp the commonalities of and differences between these formalisms.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Miyao",
                        "given": "Yusuke"
                    },
                    {
                        "family": "Genabith",
                        "given": "Josef van"
                    }
                ],
                "link": "https://aclanthology.org/P10-5001.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2010
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Cross-caption coreference resolution for automatic image understanding",
                "container-title": "",
                "page": "162-171",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Recent work in computer vision has aimed to associate image regions with keywords describing the depicted entities, but actual image ‘understanding’would also require identifying their attributes, relations and activities. Since this information cannot be conveyed by simple keywords, we have collected a corpus of “action” photos each associated with five descriptive captions. In order to obtain a consistent semantic representation for each image, we need to first identify which NPs refer to the same entities. We present three hierarchical Bayesian models for cross-caption coreference resolution. We have also created a simple ontology of entity classes that appear in images and evaluate how well these can be recovered.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hodosh",
                        "given": "Micah"
                    },
                    {
                        "family": "Young",
                        "given": "Peter"
                    },
                    {
                        "family": "Rashtchian",
                        "given": "Cyrus"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/W10-2920.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2010
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Proceedings of the NAACL HLT 2010 Student Research Workshop",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Welcome to the 2010 NAACL-HLT Student Research Workshop in Los Angeles, California! The purpose of this workshop is to provide feedback to students whose work may be in its early stages and to help prepare these students to future academic and professional pursuits. During this workshop, each presentation will be followed by a discussion on the work by a panel of senior researchers.This year, we received 20 submissions from 5 countries. We thank all authors who submitted. We are grateful to the program committee for their time, effort, and professional consideration. We also thank the panelists in advance for their time and helpful feedback. We also owe a debt of gratitude to the 2010 NAACL-HLT main conference organizers and to the National Science Foundation whose support makes many aspects of this workshop possible.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Litman",
                        "given": "Diane"
                    },
                    {
                        "family": "Boyd",
                        "given": "Adriane"
                    },
                    {
                        "family": "Joshi",
                        "given": "Mahesh"
                    },
                    {
                        "family": "Rudzicz",
                        "given": "Frank"
                    }
                ],
                "link": "https://aclanthology.org/N10-3000.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2010
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Collecting image annotations using amazon’s mechanical turk",
                "container-title": "",
                "page": "139-147",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Crowd-sourcing approaches such as Amazon’s Mechanical Turk (MTurk) make it possible to annotate or collect large amounts of linguistic data at a relatively low cost and high speed. However, MTurk offers only limited control over who is allowed to particpate in a particular task. This is particularly problematic for tasks requiring free-form text entry. Unlike multiple-choice tasks there is no correct answer, and therefore control items for which the correct answer is known cannot be used. Furthermore, MTurk has no effective built-in mechanism to guarantee workers are proficient English writers. We describe our experience in creating corpora of images annotated with multiple one-sentence descriptions on MTurk and explore the effectiveness of different quality control strategies for collecting linguistic data using Mechanical MTurk. We find that the use of a qualification test provides the highest improvement of quality, whereas refining the annotations through follow-up tasks works rather poorly. Using our best setup, we construct two image corpora, totaling more than 40,000 descriptive captions for 9000 images.",
                "DOI": "",
                "author": [
                    {
                        "family": "Rashtchian",
                        "given": "Cyrus"
                    },
                    {
                        "family": "Young",
                        "given": "Peter"
                    },
                    {
                        "family": "Hodosh",
                        "given": "Micah"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/W10-0721.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2010
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "The future role of language resources for natural language parsing (We won't be able to rely on Pierre Vinken forever... or will we have to?)",
                "container-title": "",
                "page": "13",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "The transformation that natural language parsing has undergone since the nineties would have been impossible without the availability of syntactically annotated corpora such as the Penn Treebank and similar resources for other languages. By now, it has become increasingly difficult to increase parsing accuracy on our standard data sets. But as we move to other domains of text, or aim to recover richer representations that are required for natural language understanding, it is also clear that parsing is far from being a solved task. In this panel, I would like to initiate a discussion about the kind of language resources needed to advance natural language parsing. I will also reflect on what the translation of existing resources into other grammatical representations has taught us about treebank design.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://experts.illinois.edu/en/publications/the-future-role-of-language-resources-for-natural-language-parsin",
                "issued": {
                    "date-parts": [
                        [
                            2010
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Every picture tells a story: Generating sentences from images",
                "container-title": "",
                "page": "15-29",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Humans can prepare concise descriptions of pictures, focusing on what they find important. We demonstrate that automatic methods can do so too. We describe a system that can compute a score linking an image to a sentence. This score can be used to attach a descriptive sentence to a given image, or to obtain images that illustrate a given sentence. The score is obtained by comparing an estimate of meaning obtained from the image to one obtained from the sentence. Each estimate of meaning comes from a discriminative procedure that is learned using data. We evaluate on a novel dataset consisting of human-annotated images. While our underlying estimate of meaning is impoverished, it is sufficient to produce very good quantitative results, evaluated with a novel score that can account for synecdoche.",
                "DOI": "",
                "author": [
                    {
                        "family": "Farhadi",
                        "given": "Ali"
                    },
                    {
                        "family": "Hejrati",
                        "given": "Mohsen"
                    },
                    {
                        "family": "Sadeghi",
                        "given": "Mohammad Amin"
                    },
                    {
                        "family": "Young",
                        "given": "Peter"
                    },
                    {
                        "family": "Rashtchian",
                        "given": "Cyrus"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Forsyth",
                        "given": "David"
                    }
                ],
                "link": "https://link.springer.com/chapter/10.1007/978-3-642-15561-1_2",
                "issued": {
                    "date-parts": [
                        [
                            2010
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2009,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Words and pictures: Categories, modifiers, depiction, and iconography",
                "container-title": "Object categorization: Computer and human vision perspectives",
                "page": "167-181",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Collections of digital pictures are now very common. Collections can range from a small set of family pictures, to the entire contents of a picture site like Flickr. Such collections differ from what one might see if one simply attached a camera to a robot and recorded everything, because the pictures have been selected by people. They are not necessarily “good” pictures (say, by standards of photographic aesthetics), but, because they have been chosen, they display quite strong trends. It is common for such pictures to have associated text, which might be keywords or tags but is often in the form of sentences or brief paragraphs. Text could be a caption (a set of remarks explicitly bound to the picture, and often typeset in a way that emphasizes this), region labels (terms associated with image regions, perhaps identifying what is in that region), annotations (terms associated with the whole picture, often identifying objects in the picture), or just nearby text. We review a series of ideas about how to exploit associated text to help interpret pictures.",
                "DOI": "",
                "author": [
                    {
                        "family": "Forsyth",
                        "given": "David A"
                    },
                    {
                        "family": "Berg",
                        "given": "Tamana"
                    },
                    {
                        "family": "Alm",
                        "given": "Cecilia Ovesdotter"
                    },
                    {
                        "family": "Farhadi",
                        "given": "Ali"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Loeff",
                        "given": "Nicolas"
                    },
                    {
                        "family": "Wang",
                        "given": "Gang"
                    }
                ],
                "link": "https://books.google.com/books?hl=en&lr=&id=CN9n2ZvyzlMC&oi=fnd&pg=PA167&dq=info:d2EOjJIQMy8J:scholar.google.com&ots=3L_EJteCWD&sig=oBC4g5g12z_fGGL4MhHXQbVHHos",
                "issued": {
                    "date-parts": [
                        [
                            2009
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2008,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Coling 2008: Proceedings of the workshop on cross-framework and cross-domain parser evaluation",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Broad-coverage parsing has come to a point where distinct approaches can offer (seemingly) comparable performance: statistical parsers acquired from the Penn Treebank (PTB); data-driven dependency parsers;‘deep’parsers trained off enriched treebanks (in linguistic frameworks like CCG, HPSG, or LFG); and hybrid ‘deep’parsers, employing hand-built grammars in, for example, HPSG, LFG, or LTAG. Evaluation against trees in the Wall Street Journal (WSJ) section of the PTB has helped advance parsing research over the course of the past decade. Despite some scepticism, the crisp and, over time, stable task of maximizing ParsEval metrics (ie constituent labeling precision and recall) over PTB trees has served as a dominating benchmark. However, modern treebank parsers still restrict themselves to only a subset of PTB annotation; there is reason to worry about the idiosyncrasies of this particular corpus; it remains unknown how much the ParsEval metric (or any intrinsic evaluation) can inform NLP application developers; and PTB-style analyses leave a lot to be desired in terms of linguistic information.The Grammatical Relations (GR) scheme, inspired by Dependency Grammar, offers a level of abstraction over specific syntactic analyses. It aims to capture the ‘gist’of grammatical relations in a fashion that avoids reference to a token linguistic theory. GR has recently been applied successfully in a series of cross-framework parser evaluation studies. At the same time, rather little GR gold standard data is available, and the GR scheme has been questioned for some of its design decisions. More specifically, GR builds on a combination of …",
                "DOI": "",
                "author": [
                    {
                        "family": "Bos",
                        "given": "Johan"
                    },
                    {
                        "family": "Briscoe",
                        "given": "Ted"
                    },
                    {
                        "family": "Cahill",
                        "given": "Aoife"
                    },
                    {
                        "family": "Carroll",
                        "given": "John A"
                    },
                    {
                        "family": "Clark",
                        "given": "Stephen"
                    },
                    {
                        "family": "Copestake",
                        "given": "Ann"
                    },
                    {
                        "family": "Flickinger",
                        "given": "Dan"
                    },
                    {
                        "family": "Genabith",
                        "given": "Josef van"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Joshi",
                        "given": "Aravind"
                    },
                    {
                        "family": "Kaplan",
                        "given": "Ronald M"
                    },
                    {
                        "family": "King",
                        "given": "Tracy Holloway"
                    },
                    {
                        "family": "Kuebler",
                        "given": "Sandra"
                    },
                    {
                        "family": "Lin",
                        "given": "Dekang"
                    },
                    {
                        "family": "Loenning",
                        "given": "Jan Tore"
                    },
                    {
                        "family": "Manning",
                        "given": "Christopher D"
                    },
                    {
                        "family": "Miyao",
                        "given": "Yusuke"
                    },
                    {
                        "family": "Nivre",
                        "given": "Joakim"
                    },
                    {
                        "family": "Oepen",
                        "given": "Stephan"
                    },
                    {
                        "family": "Sagae",
                        "given": "Kenji"
                    },
                    {
                        "family": "Xue",
                        "given": "Nianwen"
                    },
                    {
                        "family": "Zhang",
                        "given": "Yi"
                    }
                ],
                "link": "https://aclanthology.org/W08-1300.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2008
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Non-local scrambling: The equivalence of TAG and CCG revisited",
                "container-title": "",
                "page": "41-48",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "It is well known that standard TAG cannot deal with certain instances of longdistance scrambling in German (Rambow, 1994). That CCG can deal with many instances of non-local scrambling in languages such as Turkish has previously been observed (eg by Hoffman (1995a) and Baldridge (2002)). We show here that CCG can derive German scrambling cases which are problematic for TAG, and give CCG analyses for other German constructions that require more expressive power than TAG provides. Such analyses raise the question of the linguistic significance of the TAG-CCG equivalence. We revisit the original equivalence proof, and show that a careful examination of the translation of CCG and TAG into Indexed Grammar reveals that the IG which is strongly equivalent to CCG can generate dependencies which the corresponding IG obtained from an LTAG cannot generate.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Young",
                        "given": "Peter"
                    }
                ],
                "link": "https://aclanthology.org/W08-2306.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2008
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2007,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "CCGbank: a corpus of CCG derivations and dependency structures extracted from the Penn Treebank",
                "container-title": "Computational Linguistics",
                "page": "355-396",
                "volume": "33",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This article presents an algorithm for translating the Penn Treebank into a corpus of Combinatory Categorial Grammar (CCG) derivations augmented with local and long-range word-word dependencies. The resulting corpus, CCGbank, includes 99.4% of the sentences in the Penn Treebank. It is available from the Linguistic Data Consortium, and has been used to train wide-coverage statistical parsers that obtain state-of-the-art rates of dependency recovery.In order to obtain linguistically adequate CCG analyses, and to eliminate noise and inconsistencies in the original annotation, an extensive analysis of the constructions and annotations in the Penn Treebank was called for, and a substantial number of changes to the Treebank were necessary. We discuss the implications of our findings for the extraction of other linguistically expressive grammars from the Treebank, and for the design of future treebanks.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    }
                ],
                "link": "https://direct.mit.edu/coli/article-abstract/33/3/355/1953",
                "issued": {
                    "date-parts": [
                        [
                            2007
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Computational linguistics: a new tool for exploring biopolymer structures and statistical mechanics",
                "container-title": "",
                "page": "4289-4300",
                "volume": "48",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Unlike homopolymers, biopolymers are composed of specific sequences of different types of monomers. In proteins and RNA molecules, one-dimensional sequence information encodes a three-dimensional fold, leading to a corresponding molecular function. Such folded structures are not treated adequately through traditional methods of polymer statistical mechanics. A promising new way to solve problems of the statistical mechanics of biomolecules comes from computational linguistics, the field that uses computers to parse and understand the sentences in natural languages. Here, we give two examples. First, we show that a dynamic programming method of computational linguistics gives a fast way to search protein models for native structures. Interestingly, the computational search process closely resembles the physical folding process. Second, linguistics-based dynamic programming methods are also …",
                "DOI": "",
                "author": [
                    {
                        "family": "Dill",
                        "given": "Ken A"
                    },
                    {
                        "family": "Lucas",
                        "given": "Adam"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Huang",
                        "given": "Liang"
                    },
                    {
                        "family": "Chiang",
                        "given": "David"
                    },
                    {
                        "family": "Joshi",
                        "given": "Aravind K"
                    }
                ],
                "link": "https://www.sciencedirect.com/science/article/pii/S0032386107004648",
                "issued": {
                    "date-parts": [
                        [
                            2007
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "ACL 2007 Workshop on Deep Linguistic Processing",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This workshop was conceived with the aim of bringing together the different computational linguistic subcommunities which model language predominantly by way of theoretical syntax, either in the form of a particular theory (eg CCG, HPSG, LFG, TAG or the Prague School) or a more general framework which draws on theoretical and descriptive linguistics. We characterise this style of computational linguistic research as deep linguistic processing, due to it aspiring to model the complexity of natural language in rich linguistic representations. Aspects of this research have in the past had their own separate fora, such as the ACL 2005 workshop on deep lexical acquisition, as well as TAG+, Alpino, ParGram and DELPHIN meetings. However, since the fundamental approach of building a linguistically-founded system, as well as many of the techniques used to engineer efficient systems, are common across these projects and independent of the specific grammar formalism chosen, we felt the need for a common meeting in which experiences could be shared among a wider community.Deep linguistic processing has traditionally been concerned with grammar development for parsing and generation, with many deep processing systems using the same grammar for both directions. The linguistic precision and complexity of the grammars meant that they had to be manually developed and maintained, and were computationally expensive to run. With recent developments in computer hardware, parsing and generation algorithms and statistical learning theory, the way has been opened for deep linguistic processing to be successfully applied to an ever …",
                "DOI": "",
                "author": [
                    {
                        "family": "Baldwin",
                        "given": "Timothy"
                    },
                    {
                        "family": "Dras",
                        "given": "Mark"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "King",
                        "given": "Tracy Holloway"
                    },
                    {
                        "family": "Noord",
                        "given": "Gertjan van"
                    }
                ],
                "link": "https://aclanthology.org/W07-1200.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2007
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "The impact of deep linguistic processing on parsing technology",
                "container-title": "",
                "page": "36-38",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "As the organizers of the ACL 2007 Deep Linguistic Processing workshop (Baldwin et al., 2007), we were asked to discuss our perspectives on the role of current trends in deep linguistic processing for parsing technology. We are particularly interested in the ways in which efficient, broad coverage parsing systems for linguistically expressive grammars can be built and integrated into applications which require richer syntactic structures than shallow approaches can provide. This often requires hybrid technologies which use shallow or statistical methods for pre-or post-processing, to extend coverage, or to disambiguate the output.",
                "DOI": "",
                "author": [
                    {
                        "family": "Baldwin",
                        "given": "Timothy"
                    },
                    {
                        "family": "Dras",
                        "given": "Mark"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "King",
                        "given": "Tracy Holloway"
                    },
                    {
                        "family": "Noord",
                        "given": "Gertjan van"
                    }
                ],
                "link": "https://aclanthology.org/W07-2205.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2007
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Corpus-based evidence against sequence priming",
                "container-title": "Poster at 20th Annual CUNY Conference on Human Sentence Processing",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Syntactic priming refers to the fact that speakers are more likely to produce a target utterance with a given structure if they have previously produced (or comprehended) a prime with the same structure. In the experimental literature (eg, Bock 1986), priming has only been studied in cases where there are two semantically equivalent structural alternatives (eg, active and passive) in the prime and the target. Recent corpus-based work (Reitter et al. 2006) demonstrated that syntactic priming generalizes to the repetition of arbitrary syntactic rules in a corpus, rather than being limited to specific structural alternatives.This corpus-based approach makes it possible to address theoretical questions regarding the structural representations that are involved in syntactic priming. Chang et al.'s (2006) connectionist model of syntactic priming uses a Simple Recurrent Network to capture priming as the repetition of sequences of …",
                "DOI": "",
                "author": [
                    {
                        "family": "Reitter",
                        "given": "David"
                    },
                    {
                        "family": "Keller",
                        "given": "Frank"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://scholar.google.com/scholar?cluster=2732105879302403709&hl=en&oi=scholarr",
                "issued": {
                    "date-parts": [
                        [
                            2007
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Routes are trees: the parsing perspective on protein folding",
                "container-title": "Proteins: Structure, Function, and Bioinformatics",
                "page": "1-15",
                "volume": "66",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "An important puzzle in structural biology is the question of how proteins are able to fold so quickly into their unique native structures. There is much evidence that protein folding is hierarchic. In that case, folding routes are not linear, but have a tree structure. Trees are commonly used to represent the grammatical structure of natural language sentences, and chart parsing algorithms efficiently search the space of all possible trees for a given input string. Here we show that one such method, the CKY algorithm, can be useful both for providing novel insight into the physical protein folding process, and for computational protein structure prediction. As proof of concept, we apply this algorithm to the HP lattice model of proteins. Our algorithm identifies all direct folding route trees to the native state and allows us to construct a simple model of the folding process. Despite its simplicity, our model provides an account for the …",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Joshi",
                        "given": "Aravind K"
                    },
                    {
                        "family": "Dill",
                        "given": "Ken A"
                    }
                ],
                "link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.21195",
                "issued": {
                    "date-parts": [
                        [
                            2007
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2006,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Protein folding and chart parsing",
                "container-title": "",
                "page": "293-300",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "How can proteins fold so quickly into their unique native structures? We show here that there is a natural analogy between parsing and the protein folding problem, and demonstrate that CKY can find the native structures of a simplified lattice model of proteins with high accuracy.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Joshi",
                        "given": "Aravind"
                    },
                    {
                        "family": "Dill",
                        "given": "Ken A"
                    }
                ],
                "link": "https://aclanthology.org/W06-1635.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2006
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Priming effects in combinatory categorial grammar",
                "container-title": "",
                "page": "308-316",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper presents a corpus-based account of structural priming in human sentence processing, focusing on the role that syntactic representations play in such an account. We estimate the strength of structural priming effects from a corpus of spontaneous spoken dialogue, annotated syntactically with Combinatory Categorial Grammar (CCG) derivations. This methodology allows us to test a range of predictions that CCG makes about priming. In particular, we present evidence for priming between lexical and syntactic categories encoding partially satisfied subcategorization frames, and we show that priming effects exist both for incremental and normal-form CCG derivations.",
                "DOI": "",
                "author": [
                    {
                        "family": "Reitter",
                        "given": "David"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Keller",
                        "given": "Frank"
                    }
                ],
                "link": "https://aclanthology.org/W06-1637.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2006
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Creating a CCGbank and a wide-coverage CCG lexicon for German",
                "container-title": "",
                "page": "505-512",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We present an algorithm which creates a German CCGbank by translating the syntax graphs in the German Tiger corpus into CCG derivation trees. The resulting corpus contains 46,628 derivations, covering 95% of all complete sentences in Tiger. Lexicons extracted from this corpus contain correct lexical entries for 94% of all known tokens in unseen text.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/P06-1064.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2006
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2005,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Routes are trees: The parsing view on protein folding",
                "container-title": "13th Annual Conference on Intelligent Systems for Molecular Biology (ISMB 2005) Poster A-36",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Protein folding is a hierarchical process that builds global from local structures and is parallel at first but serial at the end. Yet, the standard description of folding routes as linear sequences of events fails to capture the parallel, recursive, nature of this process. We propose that folding routes should instead be thought of as trees, which also provides a unified account of growth and assembly. Trees are used to represent the grammatical structure of language, and we show that, like natural language sentences, proteins have specific “constituent structures”, a concept that generalizes the idea of autonomous folding units. We demonstrate that the CKY parsing algorithm [2, 5] is an efficient method to find all direct routes to the native state. CKY implements a greedy search of locally optimal conformations. The physical plausibility of this strategy is validated by the fact that it predicts the results of [4] that folding speed depends on native contact order. Since CKY returns all native routes, we can quantify the kinetic accessibility of the native state. We focus on the HP model [3], but believe that our findings can in principle be carried over to more detailed structural representations.Folding routes are trees In a folding route tree, each node corresponds to a substring of the sequence and represents a step in the folding process in which the structure of its substring was found from the structures of its children. Different branches represent independent (simultaneous) folding events. The chain “moves” from the leaves upwards:",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Joshi",
                        "given": "Aravind"
                    },
                    {
                        "family": "Dill",
                        "given": "Ken"
                    }
                ],
                "link": "https://hockenmaier.cs.illinois.edu/Papers/ISMB2005/HockenmaierJoshiDill_ISMB05_final.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2005
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Ccgbank: User’s manual",
                "container-title": "University of Pennsylvania, Philadelphia",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "CCGbank is a version of the Penn Wall Street Journal Treebank (Marcus et al., 1993) in which the standard trees have been mapped into” normal form” derivations in Combinatory Categorial Grammar (CCG, Steedman (1996, 2000)). The raison d’etre for developing CCGbank was as a resource for extracting CCG grammars (and in particular a wide-coverage CCG lexicon) and statistical head-dependency models from the WSJ treebank for use in a series of wide-coverage CCG-based parsers (Hockenmaier (2001, 2003a, b), Hockenmaier and Steedman (2002b), Clark et al.(2002), Clark and Curran (2003, 2004)), using the method pioneered by Collins (1997, 1999), Goodman (1997, 1998) and others for context-free phrase structure grammars with this more expressive grammar formalism. The point of this exercise was to deliver more accurate-wide coverage parsers capable of building interpretable structure (which standard context-free Treebank grammars do not in general do), which could then be used in applications such as question answering or summarization (Clark et al.(2004), Bos et al.(2004)). CCG categories such as (Ë\\ÆÈ)/ÆÈ, the lexical category of the transitive verb, map in a regular way to the lexical category types of other lexicalized grammar formalisms, such as the elementary trees of Lexicalized Tree-Adjoining Grammar (TAG, Joshi and Schabes (1992)) the signs of Head-driven Phrase Structure Grammar (HPSG, Pollard and Sag (1994)), and Lexical-Functional Grammar (LFG, Bresnan (1982)), among many others. Therefore CCGbank might be more readily translatable into these other frameworks for use in grammar …",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    }
                ],
                "link": "https://shannon.cs.illinois.edu/Papers/CCGbank/CCGbankManual.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2005
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "CCGbank",
                "container-title": "Linguistic Data Consortium, Philadelphia. LDC2005T13",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Blizzard Challenge 2005: Evaluating corpus-based speech synthesis on common datasets \nPage 1 Practical CCG CCGBank Tgrep2 CCG Parse Page 2 CCGBank Julia Hockenmaier \nand Mark Steedman CCGBank: translation of Penn Tree Bank to CCG Pairs syntactic \nderivations with word-word dependencies CCGBank covers 99.44% of Penn Tree Bank (and \nfixes some errors/inconsistencies) Supports Tgrep access Page 3 Example Lexical Entries \nEntry Word (mail) Category (N) Word probability (P (mail | N ) ) Category probability (P (N | \nmail) ) Word-category frequency in DB Page 4 CCGBank access Within CMU network /afs/cs.cmu.edu/academic/class/11722-s08/DATA/CCG \nManual 142 page Corpus 2713 paragraphs 48,934 sentences 83,540 lexical entries Page 5 \nTree Convertion Basic UPenn tree Page 6 Binary Branching Tree Converted to Binary \nBranching Tree Page 7 CCG Tree Re-labelled CCG tree …",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    }
                ],
                "link": "http://www.cs.cmu.edu/~./awb/11-722/ccgbank.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2005
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Grammar acquisition by child and machine",
                "container-title": "Invited Talk at the 17th European Summer School of Language, Logic and Information, Edinburgh",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "• The only way that anyone has so far been able to induce reasonably sound, wide coverage, adult-sized grammars for realistic corpora, by machine, is via Supervised Learning, based on Human-annotated data, such as that in the Penn Wall Street Journal corpus (Collins 1999; Charniak 2000).",
                "DOI": "",
                "author": [
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    },
                    {
                        "family": "Baldridge",
                        "given": "Jason"
                    },
                    {
                        "family": "Bozsahin",
                        "given": "Cem"
                    },
                    {
                        "family": "Clark",
                        "given": "Stephen"
                    },
                    {
                        "family": "Curran",
                        "given": "James"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "http://www.colag.cs.hunter.cuny.edu/psychocomp/2005/Steedman.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2005
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2004,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Extending the coverage of a CCG system",
                "container-title": "Research on Language and Computation",
                "page": "165-208",
                "volume": "2",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We demonstrate ways to enhance the coverage of a symbolic NLP system through data-intensive and machine learning techniques, while preserving the advantages of using a principled symbolic grammar formalism. We automatically acquire a large syntactic CCG lexicon from the Penn Treebank and combine it with semantic and morphological information from another hand-built lexicon using decision tree and maximum entropy classifiers. We also integrate statistical preprocessing methods in our system.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Bierner",
                        "given": "Gann"
                    },
                    {
                        "family": "Baldridger",
                        "given": "Jason"
                    }
                ],
                "link": "https://link.springer.com/article/10.1023/B:ROLC.0000016736.80096.76",
                "issued": {
                    "date-parts": [
                        [
                            2004
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Wide-coverage semantic representations from a CCG parser",
                "container-title": "",
                "page": "1240-1246",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper shows how to construct semantic representations from the derivations produced by a wide-coverage CCG parser. Unlike the dependency structures returned by the parser itself, these can be used directly for semantic interpretation. We demonstrate that well-formed semantic representations can be produced for over 97% of the sentences in unseen WSJ text. We believe this is a major step towards widecoverage semantic interpretation, one of the key objectives of the field of NLP.",
                "DOI": "",
                "author": [
                    {
                        "family": "Bos",
                        "given": "Johan"
                    },
                    {
                        "family": "Clark",
                        "given": "Stephen"
                    },
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    },
                    {
                        "family": "Curran",
                        "given": "James R"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/C04-1180.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2004
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2003,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Parsing with generative models of predicate-argument structure",
                "container-title": "",
                "page": "359-366",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "The model used by the CCG parser of Hockenmaier and Steedman (2002b) would fail to capture the correct bilexical dependencies in a language with freer word order, such as Dutch. This paper argues that probabilistic parsers should therefore model the dependencies in the predicate-argument structure, as in the model of Clark et al.(2002), and defines a generative model for CCG derivations that captures these dependencies, including bounded and unbounded long-range dependencies.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/P03-1046.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2003
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "CLSP WS-02 final report: Semi-supervised training for statistical parsing",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This project investigated co-training (Blum and Mitchell 1998) as a method for bootstrapping wide-coverage parsers initially trained on hand-labeled data. Hand-labeled data-sets—even the 1M-word Penn Wall Street Journal Treebank—are never large enough to train parsers effectively, and are expensive to produce. Automated or semi-automated methods for cheaply generating more labeled training data are an interesting alternative. Co-training is a technique originally developed for classifiers, and uses the output of two or more classifiers, initially trained on hand-labeled data, then run on (much more plentiful) unlabeled data to provide informative additional training data for each other. Crucially, the classifiers must have different models or “views” of the data to provide additional labeled data for training each other. Applying co-training to parsers raises a number of questions, since parsing is more than simple classification using a small finite set of labels. However, Sarkar (2001) showed that co-training could be used to improve performance of the LTAG parser trained on a subset of the Penn Wall Street Journal Treebank, with the TAG equivalent of a POS tagger representing the alternate view. The present project was proposed in order to investigate the conditions under which such co-training effects for parsers can be reliably obtained, and how they can be maximized.Such techniques for semi-automatically increasing the amount of training data available for training parsers are of considerable interest. Even the 1M words of the Penn WSJ corpus is arguably not enough to train adequate models, and for other languages and even other …",
                "DOI": "",
                "author": [
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    },
                    {
                        "family": "Baker",
                        "given": "Steven"
                    },
                    {
                        "family": "Crim",
                        "given": "Jeremiah"
                    },
                    {
                        "family": "Clark",
                        "given": "Stephen"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Hwa",
                        "given": "Rebecca"
                    },
                    {
                        "family": "Osborne",
                        "given": "Miles"
                    },
                    {
                        "family": "Ruhlen",
                        "given": "Paul"
                    },
                    {
                        "family": "Sarkar",
                        "given": "Anoop"
                    }
                ],
                "link": "https://www.cs.sfu.ca/~anoop/papers/pdf/jhu-ws02-report.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2003
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Semi-supervised training for statistical parsing",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Semi-Supervised Training for Statistical Parsing Page 1 Semi-Supervised Training for Statistical \nParsing Mark Steedman, Steven Baker, Jeremiah Crim, Stephen Clark, Julia Hockenmaier, \nRebecca Hwa, Miles Osborne, Paul Ruhlen, Anoop Sarkar (Edinburgh, Penn, UMD, JHU, \nCornell) August 21, 2002 Steedman et al. CLSP WS-2002 August 21, 2002 Page 2 Introduction \nMark Steedman Steedman et al. CLSP WS-2002 1 Page 3 The Team Name E-Mail Affiliation \nSteedman, Mark steedman@cogsci.ed.ac.uk University of Edinburgh Sarkar, Anoop \nanoop@linc.cis.upenn.edu University of Pennsylvania Osborne, Miles osborne@cogsci.ed.ac.uk \nUniversity of Edinburgh Hwa, Rebecca hwa@umiacs.umd.edu University of Maryland Clark, \nStephen stephenc@cogsci.ed.ac.uk University of Edinburgh Hockenmaier, Julia \njulia@cogsci.ed.ac.uk University of Edinburgh Ruhlen, Paul ruhlen@cs.jhu.edu Johns Hopkins …",
                "DOI": "",
                "author": [
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    },
                    {
                        "family": "Baker",
                        "given": "Steven"
                    },
                    {
                        "family": "Crim",
                        "given": "Jeremiah"
                    },
                    {
                        "family": "Clark",
                        "given": "Stephen"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Hwa",
                        "given": "Rebecca"
                    },
                    {
                        "family": "Osborne",
                        "given": "Miles"
                    },
                    {
                        "family": "Ruhlen",
                        "given": "Paul"
                    },
                    {
                        "family": "Sarkar",
                        "given": "Anoop"
                    }
                ],
                "link": "https://homepages.inf.ed.ac.uk/steedman/papers/cotraining/allfinal.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2003
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Example selection for bootstrapping statistical parsers",
                "container-title": "",
                "page": "236-243",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper investigates bootstrapping for statistical parsers to reduce their reliance on manually annotated training data. We consider both a mostly-unsupervised approach, co-training, in which two parsers are iteratively re-trained on each other’s output; and a semi-supervised approach, corrected co-training, in which a human corrects each parser’s output before adding it to the training data. The selection of labeled training examples is an integral part of both frameworks. We propose several selection methods based on the criteria of minimizing errors in the data and maximizing training utility. We show that incorporating the utility criterion into the selection method results in better parsers for both frameworks.",
                "DOI": "",
                "author": [
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    },
                    {
                        "family": "Hwa",
                        "given": "Rebecca"
                    },
                    {
                        "family": "Clark",
                        "given": "Stephen"
                    },
                    {
                        "family": "Osborne",
                        "given": "Miles"
                    },
                    {
                        "family": "Sarkar",
                        "given": "Anoop"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Ruhlen",
                        "given": "Paul"
                    },
                    {
                        "family": "Baker",
                        "given": "Steven"
                    },
                    {
                        "family": "Crim",
                        "given": "Jeremiah"
                    }
                ],
                "link": "https://aclanthology.org/N03-1031.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2003
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Bootstrapping statistical parsers from small datasets",
                "container-title": "",
                "page": "331-338",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We present a practical co-training method for bootstrapping statistical parsers using a small amount of manually parsed training material and a much larger pool of raw sentences. Experimental results show that unlabelled sentences can be used to improve the performance of statistical parsers. In addition, we consider the problem of bootstrapping parsers when the manually parsed training material is in a different domain to either the raw sentences or the testing material. We show that bootstrapping continues to be useful, even though no manually produced parses from the target domain are used.",
                "DOI": "",
                "author": [
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    },
                    {
                        "family": "Osborne",
                        "given": "Miles"
                    },
                    {
                        "family": "Sarkar",
                        "given": "Anoop"
                    },
                    {
                        "family": "Clark",
                        "given": "Stephen"
                    },
                    {
                        "family": "Hwa",
                        "given": "Rebecca"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Ruhlen",
                        "given": "Paul"
                    },
                    {
                        "family": "Baker",
                        "given": "Steven"
                    },
                    {
                        "family": "Crim",
                        "given": "Jeremiah"
                    }
                ],
                "link": "https://www.research.ed.ac.uk/en/publications/bootstrapping-statistical-parsers-from-small-datasets",
                "issued": {
                    "date-parts": [
                        [
                            2003
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Identifying semantic roles using combinatory categorial grammar",
                "container-title": "",
                "page": "57-64",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We present a system for automatically identifying PropBank-style semantic roles based on the output of a statistical parser for Combinatory Categorial Grammar. This system performs at least as well as a system based on a traditional Treebank parser, and outperforms it on core argument roles.",
                "DOI": "",
                "author": [
                    {
                        "family": "Gildea",
                        "given": "Daniel"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://aclanthology.org/W03-1008.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2003
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Data and models for statistical parsing with Combinatory Categorial Grammar",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This dissertation is concerned with the creation of training data and the development of probability models for statistical parsing of English with Combinatory Categorial Grammar (CCG). Parsing, or syntactic analysis, is a prerequisite for semantic interpretation, and forms therefore an integral part of any system which requires natural language understanding. Since almost all naturally occurring sentences are ambiguous, it is not sufficient (and often impossible) to generate all possible syntactic analyses. Instead, the parser needs to rank competing analyses and select only the most likely ones. A statistical parser uses a probability model to perform this task. I propose a number of ways in which such probability models can be defined for CCG. The kinds of models developed in this dissertation, generative models over normal-form derivation trees, are particularly simple, and have the further property of restricting the set of syntactic analyses to those corresponding to a canonical derivation structure. This is important to guarantee that parsing can be done efficiently. In order to achieve high parsing accuracy, a large corpus of annotated data is required to estimate the parameters of the probability models. Most existing wide-coverage statistical parsers use models of phrase-structure trees estimated from the Penn Treebank, a 1-million-word corpus of manually annotated sentences from theWall Street Journal. This dissertation presents an algorithm which translates the phrase-structure analyses of the Penn Treebank to CCG derivations. The resulting corpus, CCGbank, is used to train and test the models proposed in this dissertation. Experimental …",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://era.ed.ac.uk/handle/1842/320",
                "issued": {
                    "date-parts": [
                        [
                            2003
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2002,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Building deep dependency structures using a wide-coverage CCG parser",
                "container-title": "",
                "page": "327-334",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper describes a wide-coverage statistical parser that uses Combinatory Categorial Grammar (CCG) to derive dependency structures. The parser differs from most existing wide-coverage treebank parsers in capturing the long-range dependencies inherent in constructions such as coordination, extraction, raising and control, as well as the standard local predicate-argument dependencies. A set of dependency structures used for training and testing the parser is obtained from a treebank of CCG normal-form derivations, which have been derived (semi-) automatically from the Penn Treebank. The parser correctly recovers over 80% of labelled dependencies, and around 90% of unlabelled dependencies.",
                "DOI": "",
                "author": [
                    {
                        "family": "Clark",
                        "given": "Stephen"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    }
                ],
                "link": "https://aclanthology.org/P02-1042.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2002
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Generative models for statistical parsing with Combinatory Categorial Grammar",
                "container-title": "",
                "page": "335-342",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper compares a number of generative probability models for a widecoverage Combinatory Categorial Grammar (CCG) parser. These models are trained and tested on a corpus obtained by translating the Penn Treebank trees into CCG normal-form derivations. According to an evaluation of unlabeled word-word dependencies, our best model achieves a performance of 89.9%, comparable to the figures given by Collins (1999) for a linguistically less expressive grammar. In contrast to Gildea (2001), we find a significant improvement from modeling wordword dependencies.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    }
                ],
                "link": "https://aclanthology.org/P02-1043.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2002
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Acquiring Compact Lexicalized Grammars from a Cleaner Treebank.",
                "container-title": "LREC",
                "page": "58",
                "volume": "42",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We present an algorithm which translates the Penn Treebank into a corpus of Combinatory Categorial Grammar (CCG) derivations. To do this we have needed to make several systematic changes to the Treebank which have to effect of cleaning up a number of errors and inconsistencies. This process has yielded a cleaner treebank that can potentially be used in any framework. We also show how unary type-changing rules for certain types of modifiers can be introduced in a CCG grammar to ensure a compact lexicon without augmenting the generative power of the system. We demonstrate how the combination of preprocessing and type-changing rules minimizes the lexical coverage problem.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    }
                ],
                "link": "http://lrec.elra.info/proceedings/lrec2002/pdf/263.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2002
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Parsing with CCG",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "ฏ Combinatory Categorial Grammar (CCG, Steedman 2000b) is a “mildly context-sensitive” grammar formalism. ฏ That is, it is in a class that can plausibly be claimed to be just expressive enough to capture human language including phenomena like coordination and long range dependency.",
                "DOI": "",
                "author": [
                    {
                        "family": "Steedman",
                        "given": "Mark"
                    },
                    {
                        "family": "Clark",
                        "given": "Stephen"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=08496c264f02eb1545ae9aafa14061ea5893d0bc",
                "issued": {
                    "date-parts": [
                        [
                            2002
                        ]
                    ]
                }
            },
            {
                "id": "",
                "type": "article-journal",
                "title": "Evaluating a wide-coverage CCG parser",
                "container-title": "Proceedings of the LREC 2002 beyond PARSEVAL workshop",
                "page": "60-66",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper compares three evaluation metrics for a CCG parser trained and tested on a CCG version of the Penn Treebank. The standard Parseval metrics can be applied to the output of this parser; however, these metrics are problematic for CCG, and a comparison with scores given for standard Penn Treebank parsers is uninformative. As an alternative, we consider two evaluations based on headdependencies; one considers local dependencies defined in terms of the derivation tree, and one considers dependencies defined in terms of the CCG categories. The latter set of dependencies includes long-range dependencies such as those inherent in coordination and extraction phenomena.",
                "DOI": "",
                "author": [
                    {
                        "family": "Clark",
                        "given": "Stephen"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "http://lrec-conf.org/proceedings/lrec2002/pdf/ws20.pdf#page=64",
                "issued": {
                    "date-parts": [
                        [
                            2002
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2001,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Statistical parsing for CCG with simple generative models",
                "container-title": "",
                "page": "7-12",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "This paper presents a statistical parser for a wide-coverage combinatory categorial Grammar (ccG) derived from the Penn Treebank. The Treebank is translated to a corpus of canonical ccG derivations. We define a generative statistical model over ccG derivations and train it on the transformed Treebank. This model is evaluated using Parseval measures and the accuracy of recovery of word-word dependencies. The impact of lexical coverage on parsing accuracy is also investigated.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://www.researchgate.net/profile/Julia-Hockenmaier/publication/2524183_Statistical_Parsing_for_CCG_with_Simple_Generative_Models/links/0a85e53c6c44be618d000000/Statistical-Parsing-for-CCG-with-Simple-Generative-Models.pdf",
                "issued": {
                    "date-parts": [
                        [
                            2001
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 2000,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Providing robustness for a CCG system",
                "container-title": "Proceedings of ESSLLI’2000 Workshop on Linguistic Theory and Grammar Implementation",
                "page": "97-112",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "We demonstrate ways to preserve the advantages of using a symbolic grammar formalism as the basis of an NLP system while enhancing its robustness. We automatically acquire a CCG lexicon, combine it with semantic and morphological information from another hand-built, underspecified lexicon, and integrate it with statistical preprocessing methods.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Bierner",
                        "given": "Gann"
                    },
                    {
                        "family": "Baldridge",
                        "given": "Jason"
                    }
                ],
                "link": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=0e06967ca942ef9531562e7c30a6010a90cfc7b0",
                "issued": {
                    "date-parts": [
                        [
                            2000
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 1998,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Error-driven learning of Chinese word segmentation",
                "container-title": "",
                "page": "218-229",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "Palmer ([4]) demonstrated how Brill's Transformation-based Error-Driven Learning can be applied to word segmentation in various languages. We present experimental results which show that such algorithms can achieve satisfactory performance even with aa very dimple initial state annotator We also present two preliminary studies, which suggest that even higher performance might be achieved if simple morphological information is available to the system, and that segmentation performance might actually be improved by combining segmentation with rudimentary part-of-speech tagging.",
                "DOI": "",
                "author": [
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    },
                    {
                        "family": "Brew",
                        "given": "Chris"
                    }
                ],
                "link": "https://waseda.repo.nii.ac.jp/record/28592/files/PACLIC12-218-229.pdf",
                "issued": {
                    "date-parts": [
                        [
                            1998
                        ]
                    ]
                }
            }
        ]
    },
    {
        "year": 0,
        "pub_list": [
            {
                "id": "",
                "type": "article-journal",
                "title": "Natural Language Processing and Collaborative AI in Minecraft",
                "container-title": "",
                "page": "",
                "volume": "",
                "issue": "",
                "source": "Google Scholar",
                "abstract": "The goal of our project is to create a Builder AI and an Architect AI that can communicate between each other to create block structures in Minecraft. The architect communicates instructions to the Builder of how to create a final build structure. The Architect can observe the Builder but cannot place blocks. The Builder uses the Architect’s instructions to place blocks to build the structure. The Builder can also communicate and ask questions to the Architect in return.",
                "DOI": "",
                "author": [
                    {
                        "family": "Kaplan",
                        "given": "Elizabeth"
                    },
                    {
                        "family": "Jayannavar",
                        "given": "Prashant"
                    },
                    {
                        "family": "Hockenmaier",
                        "given": "Julia"
                    }
                ],
                "link": "https://scholar.google.com/scholar?cluster=8075260691281104969&hl=en&oi=scholarr",
                "issued": {
                    "date-parts": [
                        [
                            0
                        ]
                    ]
                }
            }
        ]
    }
]